{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Embedder\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.grid_search import GridSearchCV as GS\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures as Poly\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Model's File Location\n",
    "\n",
    "version = \"version_5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_pipeline import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/{}/word_embedder_20_new.pickle\".format(version), \"rb\") as file:\n",
    "    word_embedder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<preprocessing_pipeline.preprocessing at 0x4658c38a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.fasttext.FastText at 0x4658c38c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data To Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_for_classification=pd.read_csv(\"data/big.csv\",header=None)\n",
    "large_data_for_classification.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hardware</td>\n",
       "      <td>KINGSTON+KVR1333D3N9</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musik</td>\n",
       "      <td>power+amplifier+wisdom+</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outwear-motor</td>\n",
       "      <td>jas%20hujan%20anak</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>celana</td>\n",
       "      <td>Celana+bahan+formal</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komputer</td>\n",
       "      <td>Preset+lightroom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                        1       2\n",
       "0       hardware     KINGSTON+KVR1333D3N9  1510.0\n",
       "1          musik  power+amplifier+wisdom+    62.0\n",
       "2  outwear-motor       jas%20hujan%20anak   391.0\n",
       "3         celana      Celana+bahan+formal   288.0\n",
       "4       komputer         Preset+lightroom     1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data_for_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_category_mapper=pd.read_csv(\"category_mapping.csv\",index_col=0)\n",
    "\n",
    "category_mapper={}\n",
    "for i in raw_category_mapper.index:\n",
    "    category_mapper[raw_category_mapper[\"l2\"][i]]=raw_category_mapper[\"l1\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_category=[category_mapper[value] for value in large_data_for_classification[0]]\n",
    "large_data_for_classification[0]=new_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>komputer</td>\n",
       "      <td>KINGSTON+KVR1333D3N9</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hobi_dan_koleksi</td>\n",
       "      <td>power+amplifier+wisdom+</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor</td>\n",
       "      <td>jas%20hujan%20anak</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fashion_wanita</td>\n",
       "      <td>Celana+bahan+formal</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komputer</td>\n",
       "      <td>Preset+lightroom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                        1       2\n",
       "0          komputer     KINGSTON+KVR1333D3N9  1510.0\n",
       "1  hobi_dan_koleksi  power+amplifier+wisdom+    62.0\n",
       "2             motor       jas%20hujan%20anak   391.0\n",
       "3    fashion_wanita      Celana+bahan+formal   288.0\n",
       "4          komputer         Preset+lightroom     1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data_for_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING PUNCTUATIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 396099/396099 [00:04<00:00, 87591.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERTING SENTENCE TO VECTOR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 396099/396099 [00:14<00:00, 27776.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE VECTOR TO PANDAS DATAFRAME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#preprocess product title to 100-dimensional vector\n",
    "#and preprocess category name to integer label\n",
    "large_embedded_data, large_label_encoder = preprocessor.preprocess_data(\n",
    "    large_data_for_classification[1],\n",
    "    large_data_for_classification[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.012349</td>\n",
       "      <td>-0.758770</td>\n",
       "      <td>-0.350302</td>\n",
       "      <td>0.166808</td>\n",
       "      <td>-0.751080</td>\n",
       "      <td>-0.460484</td>\n",
       "      <td>-0.092170</td>\n",
       "      <td>-0.565020</td>\n",
       "      <td>-0.285008</td>\n",
       "      <td>-0.081576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280283</td>\n",
       "      <td>-0.186133</td>\n",
       "      <td>-0.410584</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>-0.208072</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>1.112637</td>\n",
       "      <td>0.402039</td>\n",
       "      <td>0.414983</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.795659</td>\n",
       "      <td>-2.895371</td>\n",
       "      <td>-1.744382</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>-0.306053</td>\n",
       "      <td>0.551503</td>\n",
       "      <td>-0.205609</td>\n",
       "      <td>-1.992900</td>\n",
       "      <td>-0.347923</td>\n",
       "      <td>0.280318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375908</td>\n",
       "      <td>0.806441</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>1.876183</td>\n",
       "      <td>1.148381</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.305677</td>\n",
       "      <td>-0.643420</td>\n",
       "      <td>0.623411</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.960375</td>\n",
       "      <td>-0.504543</td>\n",
       "      <td>0.515864</td>\n",
       "      <td>0.896507</td>\n",
       "      <td>0.344629</td>\n",
       "      <td>0.505430</td>\n",
       "      <td>-1.599178</td>\n",
       "      <td>-1.249479</td>\n",
       "      <td>-1.578761</td>\n",
       "      <td>2.026936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161255</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>-1.989833</td>\n",
       "      <td>0.951701</td>\n",
       "      <td>0.752408</td>\n",
       "      <td>-1.261439</td>\n",
       "      <td>1.029763</td>\n",
       "      <td>0.189695</td>\n",
       "      <td>0.723305</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.369716</td>\n",
       "      <td>-0.911321</td>\n",
       "      <td>-0.494526</td>\n",
       "      <td>-0.126446</td>\n",
       "      <td>-0.021067</td>\n",
       "      <td>0.283687</td>\n",
       "      <td>0.012714</td>\n",
       "      <td>-0.269755</td>\n",
       "      <td>-0.109006</td>\n",
       "      <td>0.688226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985987</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>-1.561995</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0.272670</td>\n",
       "      <td>1.021256</td>\n",
       "      <td>1.340632</td>\n",
       "      <td>0.985763</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.159122</td>\n",
       "      <td>-0.447368</td>\n",
       "      <td>-0.592817</td>\n",
       "      <td>0.131752</td>\n",
       "      <td>-1.350843</td>\n",
       "      <td>0.111322</td>\n",
       "      <td>-0.583496</td>\n",
       "      <td>-1.801566</td>\n",
       "      <td>0.540630</td>\n",
       "      <td>0.376193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>-0.056971</td>\n",
       "      <td>-0.586562</td>\n",
       "      <td>1.287600</td>\n",
       "      <td>0.441914</td>\n",
       "      <td>-0.338393</td>\n",
       "      <td>0.841190</td>\n",
       "      <td>1.215016</td>\n",
       "      <td>1.141698</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -1.012349 -0.758770 -0.350302  0.166808 -0.751080 -0.460484 -0.092170   \n",
       "1 -0.795659 -2.895371 -1.744382  0.395833 -0.306053  0.551503 -0.205609   \n",
       "2 -0.960375 -0.504543  0.515864  0.896507  0.344629  0.505430 -1.599178   \n",
       "3 -2.369716 -0.911321 -0.494526 -0.126446 -0.021067  0.283687  0.012714   \n",
       "4 -1.159122 -0.447368 -0.592817  0.131752 -1.350843  0.111322 -0.583496   \n",
       "\n",
       "          7         8         9   ...          91        92        93  \\\n",
       "0 -0.565020 -0.285008 -0.081576   ...   -0.280283 -0.186133 -0.410584   \n",
       "1 -1.992900 -0.347923  0.280318   ...   -0.375908  0.806441  0.564788   \n",
       "2 -1.249479 -1.578761  2.026936   ...   -0.161255  0.004695 -1.989833   \n",
       "3 -0.269755 -0.109006  0.688226   ...    0.985987  0.006689 -1.561995   \n",
       "4 -1.801566  0.540630  0.376193   ...    0.004681 -0.056971 -0.586562   \n",
       "\n",
       "         94        95        96        97        98        99  Labels  \n",
       "0  0.154500 -0.208072  0.005299  1.112637  0.402039  0.414983      10  \n",
       "1  1.876183  1.148381  0.799000  0.305677 -0.643420  0.623411       6  \n",
       "2  0.951701  0.752408 -1.261439  1.029763  0.189695  0.723305      12  \n",
       "3  0.029477  0.272670  1.021256  1.340632  0.985763  0.906968       3  \n",
       "4  1.287600  0.441914 -0.338393  0.841190  1.215016  1.141698      10  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_embedded_data[\"sum\"]=large_embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "large_embedded_data=large_embedded_data.loc[large_embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392825, 101)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_product_title_data():\n",
    "    product_title_only=pd.read_fwf('data/products2m.txt',header=None)\n",
    "    product_title_only[\"Product Title\"]=product_title_only[0]\n",
    "    product_title_only=product_title_only[[\"Product Title\"]]\n",
    "    product_title_only.dropna(inplace=True,axis=0)\n",
    "\n",
    "    dummy_category=[0 for element in tqdm.tqdm(product_title_only[\"Product Title\"])]\n",
    "\n",
    "    embedded_product_title, dummy_encoder = preprocessor.preprocess_data(\n",
    "        product_title_only[\"Product Title\"],\n",
    "        dummy_category,\n",
    "    )\n",
    "    \n",
    "    embedded_product_title[\"sum\"]=embedded_product_title.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_product_title=embedded_product_title.loc[embedded_product_title[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    embedded_product_title.drop(\"Labels\",axis=1,inplace=True)\n",
    "    \n",
    "    return embedded_product_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_semi_supervised(dataset):\n",
    "#     accepted_predictions=[]\n",
    "#     for index in tqdm.tqdm(dataset.index):\n",
    "#         predictions=[dataset[\"Prediction 1\"][index][0],\n",
    "#                             dataset[\"Prediction 2\"][index][0],\n",
    "#                             dataset[\"Prediction 3\"][index][0],\n",
    "#                             dataset[\"Prediction 4\"][index][0],\n",
    "#                             dataset[\"Prediction 1\"][index][1],\n",
    "#                             dataset[\"Prediction 2\"][index][1],\n",
    "#                             dataset[\"Prediction 3\"][index][1],\n",
    "#                             dataset[\"Prediction 4\"][index][1]]\n",
    "#         if(len(set(predictions))==2):\n",
    "#             accepted_predictions.append(dataset[\"Prediction 1\"][index][1])\n",
    "#         else:\n",
    "#             accepted_predictions.append(-1)\n",
    "#     dataset[\"Success\"]=accepted_predictions\n",
    "    \n",
    "#     base_truth=dataset[\"Base Truth\"]\n",
    "#     prediction=dataset[\"Success\"]\n",
    "    \n",
    "#     count=0\n",
    "#     total=0\n",
    "#     for index,pred in tqdm.tqdm(enumerate(prediction)):\n",
    "#         if(pred!=-1):\n",
    "#             total+=1\n",
    "#             if(pred==base_truth[index]):\n",
    "#                 count+=1\n",
    "    \n",
    "#     return count, total, len(dataset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_semi_supervised(dataset):\n",
    "    accepted_predictions=[]\n",
    "    for index in tqdm.tqdm(dataset.index):\n",
    "        predictions=[dataset[\"Prediction 1\"][index],\n",
    "                            dataset[\"Prediction 2\"][index],\n",
    "                            dataset[\"Prediction 3\"][index],\n",
    "                            dataset[\"Prediction 4\"][index],\n",
    "                            dataset[\"Prediction 5\"][index],\n",
    "                            dataset[\"Prediction 6\"][index],\n",
    "                            dataset[\"Prediction 7\"][index],\n",
    "                            dataset[\"Prediction 8\"][index],\n",
    "                            dataset[\"Prediction 9\"][index],\n",
    "                            dataset[\"Prediction 10\"][index]]\n",
    "        if(len(set(predictions))==1):\n",
    "            accepted_predictions.append(dataset[\"Prediction 1\"][index])\n",
    "        else:\n",
    "            accepted_predictions.append(-1)\n",
    "    dataset[\"Success\"]=accepted_predictions\n",
    "    \n",
    "    base_truth=dataset[\"Base Truth\"]\n",
    "    prediction=dataset[\"Success\"]\n",
    "    \n",
    "    count=0\n",
    "    total=0\n",
    "    for index,pred in tqdm.tqdm(enumerate(prediction)):\n",
    "        if(pred!=-1):\n",
    "            total+=1\n",
    "            if(pred==base_truth[index]):\n",
    "                count+=1\n",
    "    \n",
    "    return count, total, len(dataset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=large_embedded_data.copy()\n",
    "\n",
    "sampled_embedded_data=data.sample(n=len(data))\n",
    "\n",
    "nn_X_train,nn_X_test,nn_y_train,nn_y_test=train_test_split(sampled_embedded_data.drop(\"Labels\",axis=1),to_categorical(sampled_embedded_data[\"Labels\"]),test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1=nn_X_train[[*range(0,10)]]\n",
    "validation_features_1=nn_X_test[[*range(0,10)]]\n",
    "\n",
    "features_2=nn_X_train[[*range(10,20)]]\n",
    "validation_features_2=nn_X_test[[*range(10,20)]]\n",
    "\n",
    "features_3=nn_X_train[[*range(20,30)]]\n",
    "validation_features_3=nn_X_test[[*range(20,30)]]\n",
    "\n",
    "features_4=nn_X_train[[*range(30,40)]]\n",
    "validation_features_4=nn_X_test[[*range(30,40)]]\n",
    "\n",
    "features_5=nn_X_train[[*range(40,50)]]\n",
    "validation_features_5=nn_X_test[[*range(40,50)]]\n",
    "\n",
    "features_6=nn_X_train[[*range(50,60)]]\n",
    "validation_features_6=nn_X_test[[*range(50,60)]]\n",
    "\n",
    "features_7=nn_X_train[[*range(60,70)]]\n",
    "validation_features_7=nn_X_test[[*range(60,70)]]\n",
    "\n",
    "features_8=nn_X_train[[*range(70,80)]]\n",
    "validation_features_8=nn_X_test[[*range(70,80)]]\n",
    "\n",
    "features_9=nn_X_train[[*range(80,90)]]\n",
    "validation_features_9=nn_X_test[[*range(80,90)]]\n",
    "\n",
    "features_10=nn_X_train[[*range(90,100)]]\n",
    "validation_features_10=nn_X_test[[*range(90,100)]]\n",
    "\n",
    "labels=nn_y_train\n",
    "validation_labels=nn_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 51s - loss: 1.9332 - acc: 0.4221 - val_loss: 1.8544 - val_acc: 0.4447\n",
      "Epoch 2/5\n",
      " - 49s - loss: 1.8097 - acc: 0.4600 - val_loss: 1.7942 - val_acc: 0.4635\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.7600 - acc: 0.4750 - val_loss: 1.7555 - val_acc: 0.4761\n",
      "Epoch 4/5\n",
      " - 49s - loss: 1.7263 - acc: 0.4856 - val_loss: 1.7306 - val_acc: 0.4850\n",
      "Epoch 5/5\n",
      " - 49s - loss: 1.7006 - acc: 0.4932 - val_loss: 1.7112 - val_acc: 0.4907\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_1.add(Dense(500, activation='relu'))\n",
    "model_1.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_1.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_1.fit(features_1, labels, epochs=5, batch_size=100, validation_data=(validation_features_1,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 50s - loss: 1.9047 - acc: 0.4257 - val_loss: 1.8371 - val_acc: 0.4513\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.7941 - acc: 0.4649 - val_loss: 1.7817 - val_acc: 0.4706\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.7450 - acc: 0.4821 - val_loss: 1.7407 - val_acc: 0.4884\n",
      "Epoch 4/5\n",
      " - 50s - loss: 1.7115 - acc: 0.4935 - val_loss: 1.7128 - val_acc: 0.4950\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.6854 - acc: 0.5018 - val_loss: 1.6913 - val_acc: 0.5018\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_2.add(Dense(500, activation='relu'))\n",
    "model_2.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_2.fit(features_2, labels, epochs=5, batch_size=100, validation_data=(validation_features_2,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 51s - loss: 1.8915 - acc: 0.4258 - val_loss: 1.8135 - val_acc: 0.4528\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.7806 - acc: 0.4637 - val_loss: 1.7582 - val_acc: 0.4744\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.7350 - acc: 0.4792 - val_loss: 1.7306 - val_acc: 0.4840\n",
      "Epoch 4/5\n",
      " - 50s - loss: 1.7037 - acc: 0.4893 - val_loss: 1.7046 - val_acc: 0.4957\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.6792 - acc: 0.4977 - val_loss: 1.6845 - val_acc: 0.4994\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_3.add(Dense(500, activation='relu'))\n",
    "model_3.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_3.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_3.fit(features_3, labels, epochs=5, batch_size=100, validation_data=(validation_features_3,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 51s - loss: 1.9237 - acc: 0.4266 - val_loss: 1.8495 - val_acc: 0.4541\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.8103 - acc: 0.4643 - val_loss: 1.7899 - val_acc: 0.4737\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.7612 - acc: 0.4809 - val_loss: 1.7554 - val_acc: 0.4860\n",
      "Epoch 4/5\n",
      " - 50s - loss: 1.7276 - acc: 0.4917 - val_loss: 1.7270 - val_acc: 0.4939\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.7017 - acc: 0.4992 - val_loss: 1.7058 - val_acc: 0.4996\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_4.add(Dense(500, activation='relu'))\n",
    "model_4.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_4.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_4.fit(features_4, labels, epochs=5, batch_size=100, validation_data=(validation_features_4,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 51s - loss: 1.8235 - acc: 0.4499 - val_loss: 1.7464 - val_acc: 0.4753\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.7171 - acc: 0.4854 - val_loss: 1.6918 - val_acc: 0.4933\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.6724 - acc: 0.4993 - val_loss: 1.6614 - val_acc: 0.5037\n",
      "Epoch 4/5\n",
      " - 50s - loss: 1.6416 - acc: 0.5094 - val_loss: 1.6346 - val_acc: 0.5121\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.6179 - acc: 0.5176 - val_loss: 1.6179 - val_acc: 0.5192\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_5.add(Dense(500, activation='relu'))\n",
    "model_5.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_5.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_5.fit(features_5, labels, epochs=5, batch_size=100, validation_data=(validation_features_5,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 51s - loss: 1.8481 - acc: 0.4425 - val_loss: 1.7844 - val_acc: 0.4658\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.7432 - acc: 0.4773 - val_loss: 1.7300 - val_acc: 0.4865\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.6973 - acc: 0.4920 - val_loss: 1.6994 - val_acc: 0.4972\n",
      "Epoch 4/5\n",
      " - 50s - loss: 1.6655 - acc: 0.5030 - val_loss: 1.6723 - val_acc: 0.5017\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.6406 - acc: 0.5111 - val_loss: 1.6534 - val_acc: 0.5119\n"
     ]
    }
   ],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_6.add(Dense(500, activation='relu'))\n",
    "model_6.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_6.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_6.fit(features_6, labels, epochs=5, batch_size=100, validation_data=(validation_features_6,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 50s - loss: 1.8907 - acc: 0.4294 - val_loss: 1.8207 - val_acc: 0.4538\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.7809 - acc: 0.4646 - val_loss: 1.7652 - val_acc: 0.4737\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.7352 - acc: 0.4788 - val_loss: 1.7293 - val_acc: 0.4845\n",
      "Epoch 4/5\n",
      " - 49s - loss: 1.7042 - acc: 0.4893 - val_loss: 1.7055 - val_acc: 0.4948\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.6798 - acc: 0.4971 - val_loss: 1.6854 - val_acc: 0.4991\n"
     ]
    }
   ],
   "source": [
    "model_7 = Sequential()\n",
    "model_7.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_7.add(Dense(500, activation='relu'))\n",
    "model_7.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_7.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_7.fit(features_7, labels, epochs=5, batch_size=100, validation_data=(validation_features_7,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 51s - loss: 1.9596 - acc: 0.4086 - val_loss: 1.8781 - val_acc: 0.4370\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.8423 - acc: 0.4474 - val_loss: 1.8173 - val_acc: 0.4590\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.7932 - acc: 0.4646 - val_loss: 1.7824 - val_acc: 0.4712\n",
      "Epoch 4/5\n",
      " - 50s - loss: 1.7600 - acc: 0.4758 - val_loss: 1.7563 - val_acc: 0.4773\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.7343 - acc: 0.4844 - val_loss: 1.7356 - val_acc: 0.4849\n"
     ]
    }
   ],
   "source": [
    "model_8 = Sequential()\n",
    "model_8.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_8.add(Dense(500, activation='relu'))\n",
    "model_8.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_8.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_8.fit(features_8, labels, epochs=5, batch_size=100, validation_data=(validation_features_8,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 51s - loss: 1.8910 - acc: 0.4277 - val_loss: 1.8146 - val_acc: 0.4535\n",
      "Epoch 2/5\n",
      " - 50s - loss: 1.7804 - acc: 0.4638 - val_loss: 1.7574 - val_acc: 0.4738\n",
      "Epoch 3/5\n",
      " - 50s - loss: 1.7331 - acc: 0.4792 - val_loss: 1.7247 - val_acc: 0.4831\n",
      "Epoch 4/5\n",
      " - 50s - loss: 1.7004 - acc: 0.4894 - val_loss: 1.6994 - val_acc: 0.4915\n",
      "Epoch 5/5\n",
      " - 50s - loss: 1.6752 - acc: 0.4975 - val_loss: 1.6783 - val_acc: 0.5005\n"
     ]
    }
   ],
   "source": [
    "model_9 = Sequential()\n",
    "model_9.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_9.add(Dense(500, activation='relu'))\n",
    "model_9.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_9.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_9.fit(features_9, labels, epochs=5, batch_size=100, validation_data=(validation_features_9,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353542 samples, validate on 39283 samples\n",
      "Epoch 1/5\n",
      " - 52s - loss: 1.9392 - acc: 0.4109 - val_loss: 1.8803 - val_acc: 0.4298\n",
      "Epoch 2/5\n",
      " - 51s - loss: 1.8243 - acc: 0.4502 - val_loss: 1.8158 - val_acc: 0.4549\n",
      "Epoch 3/5\n",
      " - 51s - loss: 1.7757 - acc: 0.4666 - val_loss: 1.7785 - val_acc: 0.4685\n",
      "Epoch 4/5\n",
      " - 51s - loss: 1.7428 - acc: 0.4773 - val_loss: 1.7505 - val_acc: 0.4736\n",
      "Epoch 5/5\n",
      " - 51s - loss: 1.7173 - acc: 0.4858 - val_loss: 1.7325 - val_acc: 0.4800\n"
     ]
    }
   ],
   "source": [
    "model_10 = Sequential()\n",
    "model_10.add(Dense(750, input_shape=(10,), activation='relu'))\n",
    "model_10.add(Dense(500, activation='relu'))\n",
    "model_10.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_10.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model_10.fit(features_10, labels, epochs=5, batch_size=100, validation_data=(validation_features_10,validation_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_prediction=pd.DataFrame()\n",
    "# semi_supervised_prediction[\"Base Truth\"]=[np.argmax(value) for value in tqdm.tqdm(validation_labels)]\n",
    "# semi_supervised_prediction[\"Prediction 1\"]=[value.argsort()[-2:] for value in tqdm.tqdm(model_1.predict(validation_features_1))]\n",
    "# semi_supervised_prediction[\"Prediction 2\"]=[value.argsort()[-2:] for value in tqdm.tqdm(model_2.predict(validation_features_2))]\n",
    "# semi_supervised_prediction[\"Prediction 3\"]=[value.argsort()[-2:] for value in tqdm.tqdm(model_3.predict(validation_features_3))]\n",
    "# semi_supervised_prediction[\"Prediction 4\"]=[value.argsort()[-2:] for value in tqdm.tqdm(model_4.predict(validation_features_4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 39283/39283 [00:07<00:00, 5606.54it/s]\n",
      "39283it [00:00, 306083.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6531, 6856, 39283)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_semi_supervised(semi_supervised_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_classification_report(dataset):\n",
    "    accepted_predictions=[]\n",
    "    for index in tqdm.tqdm(dataset.index):\n",
    "        predictions=[dataset[\"Prediction 1\"][index],\n",
    "                            dataset[\"Prediction 2\"][index],\n",
    "                            dataset[\"Prediction 3\"][index],\n",
    "                            dataset[\"Prediction 4\"][index],\n",
    "                            dataset[\"Prediction 5\"][index],\n",
    "                            dataset[\"Prediction 6\"][index],\n",
    "                            dataset[\"Prediction 7\"][index],\n",
    "                            dataset[\"Prediction 8\"][index],\n",
    "                            dataset[\"Prediction 9\"][index],\n",
    "                            dataset[\"Prediction 10\"][index]]\n",
    "        if(len(set(predictions))==1):\n",
    "            accepted_predictions.append(dataset[\"Prediction 1\"][index])\n",
    "        else:\n",
    "            accepted_predictions.append(-1)\n",
    "    dataset[\"Success\"]=accepted_predictions\n",
    "    \n",
    "    base_truth=dataset[\"Base Truth\"]\n",
    "    prediction=dataset[\"Success\"]\n",
    "    \n",
    "    taken_base_truth=[]\n",
    "    taken_prediction=[]\n",
    "    for index,pred in tqdm.tqdm(enumerate(prediction)):\n",
    "        if(pred!=-1):\n",
    "            taken_base_truth.append(base_truth[index])\n",
    "            taken_prediction.append(pred)\n",
    "            \n",
    "    \n",
    "    print(classification_report(taken_base_truth,taken_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_dataset(model,features):\n",
    "    semi_supervised_prediction=pd.DataFrame()\n",
    "    print(\"PREDICTION 1\")\n",
    "    semi_supervised_prediction[\"Prediction 1\"]=[np.argmax(value) for value in tqdm.tqdm(model[0].predict(features[[*range(0,10)]]))]\n",
    "    print(\"PREDICTION 2\")\n",
    "    semi_supervised_prediction[\"Prediction 2\"]=[np.argmax(value) for value in tqdm.tqdm(model[1].predict(features[[*range(10,20)]]))]\n",
    "    print(\"PREDICTION 3\")\n",
    "    semi_supervised_prediction[\"Prediction 3\"]=[np.argmax(value) for value in tqdm.tqdm(model[2].predict(features[[*range(20,30)]]))]\n",
    "    print(\"PREDICTION 4\")\n",
    "    semi_supervised_prediction[\"Prediction 4\"]=[np.argmax(value) for value in tqdm.tqdm(model[3].predict(features[[*range(30,40)]]))]\n",
    "    print(\"PREDICTION 5\")\n",
    "    semi_supervised_prediction[\"Prediction 5\"]=[np.argmax(value) for value in tqdm.tqdm(model[4].predict(features[[*range(40,50)]]))]\n",
    "    print(\"PREDICTION 6\")\n",
    "    semi_supervised_prediction[\"Prediction 6\"]=[np.argmax(value) for value in tqdm.tqdm(model[5].predict(features[[*range(50,60)]]))]\n",
    "    print(\"PREDICTION 7\")\n",
    "    semi_supervised_prediction[\"Prediction 7\"]=[np.argmax(value) for value in tqdm.tqdm(model[6].predict(features[[*range(60,70)]]))]\n",
    "    print(\"PREDICTION 8\")\n",
    "    semi_supervised_prediction[\"Prediction 8\"]=[np.argmax(value) for value in tqdm.tqdm(model[7].predict(features[[*range(70,80)]]))]\n",
    "    print(\"PREDICTION 9\")\n",
    "    semi_supervised_prediction[\"Prediction 9\"]=[np.argmax(value) for value in tqdm.tqdm(model[8].predict(features[[*range(80,90)]]))]\n",
    "    print(\"PREDICTION 10\")\n",
    "    semi_supervised_prediction[\"Prediction 10\"]=[np.argmax(value) for value in tqdm.tqdm(model[9].predict(features[[*range(90,100)]]))]\n",
    "    \n",
    "    result_dataset=features.copy()\n",
    "    \n",
    "    accepted_predictions=[]\n",
    "    \n",
    "    for index in tqdm.tqdm(semi_supervised_prediction.index):\n",
    "        predictions=[semi_supervised_prediction[\"Prediction {}\".format(i)][index] for i in range(1,10+1)]\n",
    "        \n",
    "        if(len(set(predictions))==1):\n",
    "            accepted_predictions.append(semi_supervised_prediction[\"Prediction 1\"][index])\n",
    "        else:\n",
    "            accepted_predictions.append(-1)\n",
    "            \n",
    "    result_dataset[\"Labels\"]=accepted_predictions\n",
    "    \n",
    "    result_dataset=result_dataset.loc[result_dataset[\"Labels\"]!=-1]\n",
    "    \n",
    "    return result_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[model_1,model_2,model_3,model_4,model_5,model_6,model_7,model_8,model_9,model_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:00<00:00, 404530.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:00<00:00, 427052.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:00<00:00, 412906.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:00<00:00, 403704.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:01<00:00, 392585.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:01<00:00, 379872.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:01<00:00, 374875.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:01<00:00, 374523.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:01<00:00, 374875.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 399931/399931 [00:01<00:00, 381262.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 399931/399931 [01:13<00:00, 5414.28it/s]\n"
     ]
    }
   ],
   "source": [
    "additional_dataset = semi_supervised_dataset(models,embedded_product_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-1.049690</td>\n",
       "      <td>-0.771513</td>\n",
       "      <td>0.158670</td>\n",
       "      <td>-0.312674</td>\n",
       "      <td>-0.377480</td>\n",
       "      <td>-0.369302</td>\n",
       "      <td>0.280022</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>-0.913724</td>\n",
       "      <td>0.979315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280885</td>\n",
       "      <td>1.201361</td>\n",
       "      <td>0.932319</td>\n",
       "      <td>1.638536</td>\n",
       "      <td>0.913610</td>\n",
       "      <td>0.610413</td>\n",
       "      <td>0.355339</td>\n",
       "      <td>-0.137420</td>\n",
       "      <td>0.647466</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-2.478013</td>\n",
       "      <td>-0.043695</td>\n",
       "      <td>0.771950</td>\n",
       "      <td>-2.139385</td>\n",
       "      <td>1.071926</td>\n",
       "      <td>3.770401</td>\n",
       "      <td>0.168407</td>\n",
       "      <td>-2.631820</td>\n",
       "      <td>0.614697</td>\n",
       "      <td>2.824265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.973839</td>\n",
       "      <td>-1.481487</td>\n",
       "      <td>-1.533303</td>\n",
       "      <td>0.760727</td>\n",
       "      <td>-1.990130</td>\n",
       "      <td>0.780788</td>\n",
       "      <td>0.430325</td>\n",
       "      <td>1.497166</td>\n",
       "      <td>0.265564</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-1.255681</td>\n",
       "      <td>-0.777635</td>\n",
       "      <td>-0.877367</td>\n",
       "      <td>-0.462382</td>\n",
       "      <td>-0.081313</td>\n",
       "      <td>-0.237224</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>-0.343707</td>\n",
       "      <td>0.083085</td>\n",
       "      <td>1.299823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153772</td>\n",
       "      <td>0.059088</td>\n",
       "      <td>0.626004</td>\n",
       "      <td>0.983645</td>\n",
       "      <td>0.570106</td>\n",
       "      <td>-0.825074</td>\n",
       "      <td>1.247822</td>\n",
       "      <td>0.274666</td>\n",
       "      <td>0.839839</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-2.253641</td>\n",
       "      <td>-1.181772</td>\n",
       "      <td>-1.492457</td>\n",
       "      <td>0.818130</td>\n",
       "      <td>-0.904294</td>\n",
       "      <td>1.049954</td>\n",
       "      <td>-0.735170</td>\n",
       "      <td>1.372616</td>\n",
       "      <td>0.335229</td>\n",
       "      <td>1.417195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478855</td>\n",
       "      <td>-0.081880</td>\n",
       "      <td>0.218353</td>\n",
       "      <td>1.944819</td>\n",
       "      <td>0.459990</td>\n",
       "      <td>-1.591547</td>\n",
       "      <td>1.275095</td>\n",
       "      <td>-0.146483</td>\n",
       "      <td>0.567948</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>-1.196334</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>-0.396672</td>\n",
       "      <td>-0.385498</td>\n",
       "      <td>-0.167445</td>\n",
       "      <td>0.282152</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.122284</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>0.774006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719216</td>\n",
       "      <td>-0.064531</td>\n",
       "      <td>-0.269396</td>\n",
       "      <td>0.155455</td>\n",
       "      <td>0.313454</td>\n",
       "      <td>0.991185</td>\n",
       "      <td>0.885388</td>\n",
       "      <td>1.073633</td>\n",
       "      <td>0.327812</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>-0.257420</td>\n",
       "      <td>-0.445647</td>\n",
       "      <td>-0.404965</td>\n",
       "      <td>0.293855</td>\n",
       "      <td>0.203597</td>\n",
       "      <td>1.385421</td>\n",
       "      <td>0.550570</td>\n",
       "      <td>0.094740</td>\n",
       "      <td>0.229750</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231441</td>\n",
       "      <td>-0.762304</td>\n",
       "      <td>-0.827463</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.141893</td>\n",
       "      <td>-0.036272</td>\n",
       "      <td>0.270480</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>-0.195311</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>-3.743620</td>\n",
       "      <td>-1.367480</td>\n",
       "      <td>-2.360441</td>\n",
       "      <td>0.530165</td>\n",
       "      <td>1.211634</td>\n",
       "      <td>-0.313798</td>\n",
       "      <td>-2.481249</td>\n",
       "      <td>-3.569509</td>\n",
       "      <td>0.605719</td>\n",
       "      <td>2.864000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767673</td>\n",
       "      <td>1.146606</td>\n",
       "      <td>1.577477</td>\n",
       "      <td>1.893352</td>\n",
       "      <td>-0.035766</td>\n",
       "      <td>-1.228378</td>\n",
       "      <td>4.257276</td>\n",
       "      <td>-0.839938</td>\n",
       "      <td>1.080752</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>-2.728978</td>\n",
       "      <td>-1.179033</td>\n",
       "      <td>-2.405885</td>\n",
       "      <td>-0.344301</td>\n",
       "      <td>0.077061</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>-1.370032</td>\n",
       "      <td>-2.781253</td>\n",
       "      <td>0.605790</td>\n",
       "      <td>2.134533</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082223</td>\n",
       "      <td>1.320488</td>\n",
       "      <td>0.638416</td>\n",
       "      <td>1.844516</td>\n",
       "      <td>-0.514469</td>\n",
       "      <td>-0.896418</td>\n",
       "      <td>4.258131</td>\n",
       "      <td>-0.478206</td>\n",
       "      <td>0.798461</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>-2.849284</td>\n",
       "      <td>-0.879398</td>\n",
       "      <td>-1.815585</td>\n",
       "      <td>0.139728</td>\n",
       "      <td>-0.131045</td>\n",
       "      <td>0.958549</td>\n",
       "      <td>0.816506</td>\n",
       "      <td>-0.050087</td>\n",
       "      <td>-1.026676</td>\n",
       "      <td>1.160616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.738908</td>\n",
       "      <td>-1.800838</td>\n",
       "      <td>-0.707670</td>\n",
       "      <td>1.204473</td>\n",
       "      <td>1.884565</td>\n",
       "      <td>1.121318</td>\n",
       "      <td>0.464986</td>\n",
       "      <td>1.230489</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>-4.064809</td>\n",
       "      <td>-1.815839</td>\n",
       "      <td>0.205814</td>\n",
       "      <td>2.079911</td>\n",
       "      <td>-1.302466</td>\n",
       "      <td>1.661439</td>\n",
       "      <td>-1.536190</td>\n",
       "      <td>-0.972196</td>\n",
       "      <td>-1.475644</td>\n",
       "      <td>1.063404</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.979713</td>\n",
       "      <td>-1.056393</td>\n",
       "      <td>0.377808</td>\n",
       "      <td>1.726000</td>\n",
       "      <td>3.398573</td>\n",
       "      <td>-2.573513</td>\n",
       "      <td>0.981770</td>\n",
       "      <td>0.667107</td>\n",
       "      <td>0.868972</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>-1.049337</td>\n",
       "      <td>-0.034050</td>\n",
       "      <td>-0.946103</td>\n",
       "      <td>-0.727392</td>\n",
       "      <td>-1.949147</td>\n",
       "      <td>0.593835</td>\n",
       "      <td>-0.335773</td>\n",
       "      <td>-3.115400</td>\n",
       "      <td>-2.332368</td>\n",
       "      <td>1.797949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050593</td>\n",
       "      <td>-1.129677</td>\n",
       "      <td>1.237034</td>\n",
       "      <td>0.911729</td>\n",
       "      <td>0.794443</td>\n",
       "      <td>-0.850870</td>\n",
       "      <td>2.168645</td>\n",
       "      <td>-0.224972</td>\n",
       "      <td>2.464960</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-2.113971</td>\n",
       "      <td>-0.149115</td>\n",
       "      <td>-0.425182</td>\n",
       "      <td>0.728214</td>\n",
       "      <td>0.260170</td>\n",
       "      <td>0.096754</td>\n",
       "      <td>-1.521641</td>\n",
       "      <td>-2.434401</td>\n",
       "      <td>0.862704</td>\n",
       "      <td>1.843156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098151</td>\n",
       "      <td>-0.121465</td>\n",
       "      <td>0.680853</td>\n",
       "      <td>0.308391</td>\n",
       "      <td>-0.376037</td>\n",
       "      <td>-1.516559</td>\n",
       "      <td>3.123985</td>\n",
       "      <td>-0.650126</td>\n",
       "      <td>0.258620</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>-1.175175</td>\n",
       "      <td>-0.876603</td>\n",
       "      <td>-1.170906</td>\n",
       "      <td>-0.997286</td>\n",
       "      <td>-0.748919</td>\n",
       "      <td>-0.168592</td>\n",
       "      <td>-0.450506</td>\n",
       "      <td>-0.319784</td>\n",
       "      <td>0.041448</td>\n",
       "      <td>2.472831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316502</td>\n",
       "      <td>-0.904556</td>\n",
       "      <td>1.267430</td>\n",
       "      <td>1.378718</td>\n",
       "      <td>0.303729</td>\n",
       "      <td>-0.875339</td>\n",
       "      <td>2.233519</td>\n",
       "      <td>0.477678</td>\n",
       "      <td>1.549089</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>-2.025106</td>\n",
       "      <td>0.395679</td>\n",
       "      <td>-2.377700</td>\n",
       "      <td>1.719629</td>\n",
       "      <td>-1.537529</td>\n",
       "      <td>0.887685</td>\n",
       "      <td>-2.255765</td>\n",
       "      <td>-1.024681</td>\n",
       "      <td>2.091985</td>\n",
       "      <td>2.069914</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.952944</td>\n",
       "      <td>-2.167449</td>\n",
       "      <td>-0.821809</td>\n",
       "      <td>-0.893908</td>\n",
       "      <td>0.392775</td>\n",
       "      <td>-0.435671</td>\n",
       "      <td>1.102706</td>\n",
       "      <td>3.499334</td>\n",
       "      <td>4.208037</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>-1.988590</td>\n",
       "      <td>0.272053</td>\n",
       "      <td>-1.480868</td>\n",
       "      <td>0.399932</td>\n",
       "      <td>-1.882465</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>0.137399</td>\n",
       "      <td>-1.603543</td>\n",
       "      <td>-1.241909</td>\n",
       "      <td>0.522514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393627</td>\n",
       "      <td>-1.027048</td>\n",
       "      <td>1.318500</td>\n",
       "      <td>0.524059</td>\n",
       "      <td>1.555427</td>\n",
       "      <td>0.041495</td>\n",
       "      <td>1.978925</td>\n",
       "      <td>-0.427646</td>\n",
       "      <td>2.253969</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>-5.887641</td>\n",
       "      <td>-1.946310</td>\n",
       "      <td>2.034301</td>\n",
       "      <td>-0.684665</td>\n",
       "      <td>-0.648630</td>\n",
       "      <td>-0.100018</td>\n",
       "      <td>-1.938350</td>\n",
       "      <td>-1.899691</td>\n",
       "      <td>-0.989534</td>\n",
       "      <td>3.401803</td>\n",
       "      <td>...</td>\n",
       "      <td>2.511203</td>\n",
       "      <td>-2.588614</td>\n",
       "      <td>-3.134518</td>\n",
       "      <td>1.402726</td>\n",
       "      <td>-0.007625</td>\n",
       "      <td>1.710679</td>\n",
       "      <td>0.138814</td>\n",
       "      <td>0.775336</td>\n",
       "      <td>0.300810</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>-1.042665</td>\n",
       "      <td>0.109254</td>\n",
       "      <td>-0.151601</td>\n",
       "      <td>-0.647027</td>\n",
       "      <td>0.780285</td>\n",
       "      <td>1.541363</td>\n",
       "      <td>0.353203</td>\n",
       "      <td>-1.391314</td>\n",
       "      <td>0.398150</td>\n",
       "      <td>1.228879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414465</td>\n",
       "      <td>-0.345195</td>\n",
       "      <td>-1.032897</td>\n",
       "      <td>-0.343206</td>\n",
       "      <td>-0.863417</td>\n",
       "      <td>-0.467653</td>\n",
       "      <td>0.086490</td>\n",
       "      <td>0.130265</td>\n",
       "      <td>0.459209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>-1.962819</td>\n",
       "      <td>-1.026993</td>\n",
       "      <td>-1.287164</td>\n",
       "      <td>-1.371570</td>\n",
       "      <td>0.844003</td>\n",
       "      <td>1.967685</td>\n",
       "      <td>-0.803276</td>\n",
       "      <td>-1.455131</td>\n",
       "      <td>0.405860</td>\n",
       "      <td>1.316828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522909</td>\n",
       "      <td>-1.431578</td>\n",
       "      <td>-0.945789</td>\n",
       "      <td>1.212372</td>\n",
       "      <td>-1.319644</td>\n",
       "      <td>-0.035256</td>\n",
       "      <td>1.272448</td>\n",
       "      <td>0.664281</td>\n",
       "      <td>1.198406</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>-0.135766</td>\n",
       "      <td>-2.134075</td>\n",
       "      <td>-0.916568</td>\n",
       "      <td>0.936112</td>\n",
       "      <td>-0.238095</td>\n",
       "      <td>0.958329</td>\n",
       "      <td>0.601731</td>\n",
       "      <td>0.508158</td>\n",
       "      <td>-0.084861</td>\n",
       "      <td>0.039660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110006</td>\n",
       "      <td>-1.141496</td>\n",
       "      <td>0.489964</td>\n",
       "      <td>0.867882</td>\n",
       "      <td>0.920993</td>\n",
       "      <td>-0.280907</td>\n",
       "      <td>1.083940</td>\n",
       "      <td>1.092334</td>\n",
       "      <td>0.416514</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-0.793785</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>-0.102379</td>\n",
       "      <td>-0.789162</td>\n",
       "      <td>0.067272</td>\n",
       "      <td>1.630809</td>\n",
       "      <td>-0.418927</td>\n",
       "      <td>-0.691452</td>\n",
       "      <td>0.724723</td>\n",
       "      <td>2.145714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513361</td>\n",
       "      <td>-0.637113</td>\n",
       "      <td>-1.111747</td>\n",
       "      <td>0.277987</td>\n",
       "      <td>-0.594351</td>\n",
       "      <td>-0.152484</td>\n",
       "      <td>-0.222506</td>\n",
       "      <td>0.422848</td>\n",
       "      <td>0.361659</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>-3.384265</td>\n",
       "      <td>-2.492061</td>\n",
       "      <td>-1.038584</td>\n",
       "      <td>-0.300156</td>\n",
       "      <td>0.093111</td>\n",
       "      <td>-0.100909</td>\n",
       "      <td>0.261836</td>\n",
       "      <td>-2.989679</td>\n",
       "      <td>-1.269629</td>\n",
       "      <td>0.222143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596686</td>\n",
       "      <td>1.121777</td>\n",
       "      <td>0.569784</td>\n",
       "      <td>0.980308</td>\n",
       "      <td>0.805499</td>\n",
       "      <td>-0.906797</td>\n",
       "      <td>3.203183</td>\n",
       "      <td>-0.313417</td>\n",
       "      <td>1.292847</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>-0.301632</td>\n",
       "      <td>-0.318571</td>\n",
       "      <td>-0.436904</td>\n",
       "      <td>-0.311855</td>\n",
       "      <td>-0.208266</td>\n",
       "      <td>0.501674</td>\n",
       "      <td>-0.294672</td>\n",
       "      <td>-0.059025</td>\n",
       "      <td>0.066760</td>\n",
       "      <td>-0.185457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161395</td>\n",
       "      <td>-0.399576</td>\n",
       "      <td>0.200129</td>\n",
       "      <td>0.381431</td>\n",
       "      <td>1.089576</td>\n",
       "      <td>-0.026140</td>\n",
       "      <td>1.146891</td>\n",
       "      <td>-0.080369</td>\n",
       "      <td>0.501096</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>-0.301632</td>\n",
       "      <td>-0.318571</td>\n",
       "      <td>-0.436904</td>\n",
       "      <td>-0.311855</td>\n",
       "      <td>-0.208266</td>\n",
       "      <td>0.501674</td>\n",
       "      <td>-0.294672</td>\n",
       "      <td>-0.059025</td>\n",
       "      <td>0.066760</td>\n",
       "      <td>-0.185457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161395</td>\n",
       "      <td>-0.399576</td>\n",
       "      <td>0.200129</td>\n",
       "      <td>0.381431</td>\n",
       "      <td>1.089576</td>\n",
       "      <td>-0.026140</td>\n",
       "      <td>1.146891</td>\n",
       "      <td>-0.080369</td>\n",
       "      <td>0.501096</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-1.432631</td>\n",
       "      <td>-0.244971</td>\n",
       "      <td>-0.686108</td>\n",
       "      <td>-0.244268</td>\n",
       "      <td>0.034909</td>\n",
       "      <td>1.100058</td>\n",
       "      <td>-0.239596</td>\n",
       "      <td>-0.583594</td>\n",
       "      <td>-0.181081</td>\n",
       "      <td>1.401062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187933</td>\n",
       "      <td>-1.366067</td>\n",
       "      <td>-0.950168</td>\n",
       "      <td>0.080710</td>\n",
       "      <td>-1.656925</td>\n",
       "      <td>-0.077629</td>\n",
       "      <td>0.927300</td>\n",
       "      <td>0.648066</td>\n",
       "      <td>0.792139</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>-2.784023</td>\n",
       "      <td>-5.867600</td>\n",
       "      <td>-0.891076</td>\n",
       "      <td>4.803305</td>\n",
       "      <td>0.676565</td>\n",
       "      <td>3.405698</td>\n",
       "      <td>0.064993</td>\n",
       "      <td>0.627836</td>\n",
       "      <td>0.956686</td>\n",
       "      <td>1.186856</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.492768</td>\n",
       "      <td>-4.440834</td>\n",
       "      <td>0.329444</td>\n",
       "      <td>-0.305374</td>\n",
       "      <td>5.432211</td>\n",
       "      <td>4.376016</td>\n",
       "      <td>4.416584</td>\n",
       "      <td>1.141813</td>\n",
       "      <td>3.076368</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>-0.859272</td>\n",
       "      <td>-0.592162</td>\n",
       "      <td>-0.538060</td>\n",
       "      <td>-0.909108</td>\n",
       "      <td>-0.054383</td>\n",
       "      <td>1.126245</td>\n",
       "      <td>0.389288</td>\n",
       "      <td>-0.898213</td>\n",
       "      <td>-0.332280</td>\n",
       "      <td>0.187639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.547992</td>\n",
       "      <td>-0.564989</td>\n",
       "      <td>-0.865920</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.642486</td>\n",
       "      <td>-0.108232</td>\n",
       "      <td>0.703986</td>\n",
       "      <td>0.139774</td>\n",
       "      <td>1.114346</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>-2.032157</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>-0.682422</td>\n",
       "      <td>0.574182</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>-0.653287</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>-1.703599</td>\n",
       "      <td>-0.086172</td>\n",
       "      <td>1.116697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196534</td>\n",
       "      <td>-0.431074</td>\n",
       "      <td>-0.043430</td>\n",
       "      <td>0.638944</td>\n",
       "      <td>0.708614</td>\n",
       "      <td>-0.265638</td>\n",
       "      <td>2.000774</td>\n",
       "      <td>-0.309918</td>\n",
       "      <td>0.039013</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>-0.649767</td>\n",
       "      <td>-0.912867</td>\n",
       "      <td>-0.961072</td>\n",
       "      <td>0.227151</td>\n",
       "      <td>-0.937122</td>\n",
       "      <td>-0.122507</td>\n",
       "      <td>0.068271</td>\n",
       "      <td>-0.622851</td>\n",
       "      <td>-0.314905</td>\n",
       "      <td>1.006329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150122</td>\n",
       "      <td>-0.174207</td>\n",
       "      <td>1.061313</td>\n",
       "      <td>0.412757</td>\n",
       "      <td>0.808535</td>\n",
       "      <td>-0.309061</td>\n",
       "      <td>0.254641</td>\n",
       "      <td>0.762193</td>\n",
       "      <td>0.656666</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>-2.176965</td>\n",
       "      <td>-0.810508</td>\n",
       "      <td>-1.050303</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>-0.052324</td>\n",
       "      <td>0.136931</td>\n",
       "      <td>-1.237619</td>\n",
       "      <td>-1.505365</td>\n",
       "      <td>0.237543</td>\n",
       "      <td>1.966551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020130</td>\n",
       "      <td>0.425620</td>\n",
       "      <td>0.542820</td>\n",
       "      <td>1.081372</td>\n",
       "      <td>-0.592904</td>\n",
       "      <td>-0.874931</td>\n",
       "      <td>1.129879</td>\n",
       "      <td>-0.616982</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>-0.679589</td>\n",
       "      <td>-0.219330</td>\n",
       "      <td>0.032546</td>\n",
       "      <td>-0.569294</td>\n",
       "      <td>-0.937822</td>\n",
       "      <td>1.248770</td>\n",
       "      <td>-0.672257</td>\n",
       "      <td>-0.345671</td>\n",
       "      <td>0.350842</td>\n",
       "      <td>-0.187192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205031</td>\n",
       "      <td>-0.267118</td>\n",
       "      <td>-0.613532</td>\n",
       "      <td>0.663867</td>\n",
       "      <td>0.974826</td>\n",
       "      <td>0.223761</td>\n",
       "      <td>0.382849</td>\n",
       "      <td>0.180882</td>\n",
       "      <td>0.238202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398725</th>\n",
       "      <td>-1.146187</td>\n",
       "      <td>-1.425933</td>\n",
       "      <td>-0.508930</td>\n",
       "      <td>0.611420</td>\n",
       "      <td>0.167838</td>\n",
       "      <td>0.970509</td>\n",
       "      <td>-0.819843</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.168435</td>\n",
       "      <td>0.426074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>-0.051900</td>\n",
       "      <td>-0.441303</td>\n",
       "      <td>0.785960</td>\n",
       "      <td>0.177157</td>\n",
       "      <td>-0.982575</td>\n",
       "      <td>0.710367</td>\n",
       "      <td>0.949398</td>\n",
       "      <td>-0.029121</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398733</th>\n",
       "      <td>-1.735178</td>\n",
       "      <td>1.195967</td>\n",
       "      <td>-1.600164</td>\n",
       "      <td>-0.151935</td>\n",
       "      <td>-2.318790</td>\n",
       "      <td>1.312073</td>\n",
       "      <td>1.100908</td>\n",
       "      <td>-1.008126</td>\n",
       "      <td>-0.958141</td>\n",
       "      <td>0.082558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802012</td>\n",
       "      <td>-0.692856</td>\n",
       "      <td>0.570078</td>\n",
       "      <td>1.033969</td>\n",
       "      <td>1.572861</td>\n",
       "      <td>0.630344</td>\n",
       "      <td>2.433918</td>\n",
       "      <td>-0.498809</td>\n",
       "      <td>0.975340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398763</th>\n",
       "      <td>-1.217626</td>\n",
       "      <td>0.201986</td>\n",
       "      <td>-0.688823</td>\n",
       "      <td>-1.219053</td>\n",
       "      <td>0.643099</td>\n",
       "      <td>3.286798</td>\n",
       "      <td>0.077760</td>\n",
       "      <td>-1.470432</td>\n",
       "      <td>0.746922</td>\n",
       "      <td>2.925592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.319505</td>\n",
       "      <td>-0.035759</td>\n",
       "      <td>-1.320024</td>\n",
       "      <td>-0.156371</td>\n",
       "      <td>-1.578767</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>-0.597357</td>\n",
       "      <td>1.640970</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398768</th>\n",
       "      <td>-1.049690</td>\n",
       "      <td>-0.771513</td>\n",
       "      <td>0.158670</td>\n",
       "      <td>-0.312674</td>\n",
       "      <td>-0.377480</td>\n",
       "      <td>-0.369302</td>\n",
       "      <td>0.280022</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>-0.913724</td>\n",
       "      <td>0.979315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280885</td>\n",
       "      <td>1.201361</td>\n",
       "      <td>0.932319</td>\n",
       "      <td>1.638536</td>\n",
       "      <td>0.913610</td>\n",
       "      <td>0.610413</td>\n",
       "      <td>0.355339</td>\n",
       "      <td>-0.137420</td>\n",
       "      <td>0.647466</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398853</th>\n",
       "      <td>-0.257710</td>\n",
       "      <td>-0.017807</td>\n",
       "      <td>-0.004450</td>\n",
       "      <td>-0.243110</td>\n",
       "      <td>0.298243</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>-0.364747</td>\n",
       "      <td>0.115877</td>\n",
       "      <td>0.448329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048217</td>\n",
       "      <td>-0.216032</td>\n",
       "      <td>-0.310807</td>\n",
       "      <td>-0.009107</td>\n",
       "      <td>-0.284626</td>\n",
       "      <td>-0.012712</td>\n",
       "      <td>-0.260300</td>\n",
       "      <td>0.210753</td>\n",
       "      <td>-0.074270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398866</th>\n",
       "      <td>-0.704512</td>\n",
       "      <td>-0.272402</td>\n",
       "      <td>-0.398904</td>\n",
       "      <td>-0.257414</td>\n",
       "      <td>-1.266904</td>\n",
       "      <td>0.741954</td>\n",
       "      <td>0.472652</td>\n",
       "      <td>0.283822</td>\n",
       "      <td>-0.182845</td>\n",
       "      <td>0.473933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437301</td>\n",
       "      <td>-0.063556</td>\n",
       "      <td>0.083362</td>\n",
       "      <td>-0.413158</td>\n",
       "      <td>0.562542</td>\n",
       "      <td>0.420663</td>\n",
       "      <td>0.204915</td>\n",
       "      <td>0.469280</td>\n",
       "      <td>0.647910</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398910</th>\n",
       "      <td>-0.750507</td>\n",
       "      <td>0.077556</td>\n",
       "      <td>-0.189132</td>\n",
       "      <td>-0.509335</td>\n",
       "      <td>0.152268</td>\n",
       "      <td>1.351847</td>\n",
       "      <td>-0.225641</td>\n",
       "      <td>-0.593324</td>\n",
       "      <td>0.359630</td>\n",
       "      <td>1.465795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211838</td>\n",
       "      <td>-0.462109</td>\n",
       "      <td>-0.663366</td>\n",
       "      <td>-0.166433</td>\n",
       "      <td>-0.298871</td>\n",
       "      <td>-0.248243</td>\n",
       "      <td>-0.266417</td>\n",
       "      <td>-0.039466</td>\n",
       "      <td>0.183937</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398993</th>\n",
       "      <td>-0.257420</td>\n",
       "      <td>-0.445647</td>\n",
       "      <td>-0.404965</td>\n",
       "      <td>0.293855</td>\n",
       "      <td>0.203597</td>\n",
       "      <td>1.385421</td>\n",
       "      <td>0.550570</td>\n",
       "      <td>0.094740</td>\n",
       "      <td>0.229750</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231441</td>\n",
       "      <td>-0.762304</td>\n",
       "      <td>-0.827463</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.141893</td>\n",
       "      <td>-0.036272</td>\n",
       "      <td>0.270480</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>-0.195311</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399002</th>\n",
       "      <td>-0.959470</td>\n",
       "      <td>-0.552836</td>\n",
       "      <td>-0.915317</td>\n",
       "      <td>0.131137</td>\n",
       "      <td>-0.527347</td>\n",
       "      <td>0.085283</td>\n",
       "      <td>-0.116752</td>\n",
       "      <td>-0.548992</td>\n",
       "      <td>-0.213859</td>\n",
       "      <td>0.853386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.119292</td>\n",
       "      <td>1.136510</td>\n",
       "      <td>-0.170949</td>\n",
       "      <td>1.284367</td>\n",
       "      <td>0.112111</td>\n",
       "      <td>0.887319</td>\n",
       "      <td>0.301567</td>\n",
       "      <td>0.807245</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399034</th>\n",
       "      <td>0.293867</td>\n",
       "      <td>0.383818</td>\n",
       "      <td>-0.598053</td>\n",
       "      <td>2.049648</td>\n",
       "      <td>-1.057692</td>\n",
       "      <td>-1.063475</td>\n",
       "      <td>-1.151902</td>\n",
       "      <td>-0.922707</td>\n",
       "      <td>-1.129242</td>\n",
       "      <td>-0.733469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233165</td>\n",
       "      <td>-1.369149</td>\n",
       "      <td>-1.223982</td>\n",
       "      <td>1.707901</td>\n",
       "      <td>1.303650</td>\n",
       "      <td>-0.742352</td>\n",
       "      <td>2.671120</td>\n",
       "      <td>-0.675203</td>\n",
       "      <td>1.476823</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399051</th>\n",
       "      <td>-0.695505</td>\n",
       "      <td>-0.612101</td>\n",
       "      <td>0.031835</td>\n",
       "      <td>-0.371482</td>\n",
       "      <td>-0.028178</td>\n",
       "      <td>0.359439</td>\n",
       "      <td>0.746080</td>\n",
       "      <td>-1.075386</td>\n",
       "      <td>0.128655</td>\n",
       "      <td>0.435903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304475</td>\n",
       "      <td>-0.285431</td>\n",
       "      <td>-0.333920</td>\n",
       "      <td>0.807024</td>\n",
       "      <td>0.268054</td>\n",
       "      <td>0.296205</td>\n",
       "      <td>0.357785</td>\n",
       "      <td>0.633814</td>\n",
       "      <td>0.447008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399055</th>\n",
       "      <td>-2.111944</td>\n",
       "      <td>-0.765627</td>\n",
       "      <td>-1.180691</td>\n",
       "      <td>0.108773</td>\n",
       "      <td>-0.963621</td>\n",
       "      <td>0.241166</td>\n",
       "      <td>-1.957313</td>\n",
       "      <td>-1.676918</td>\n",
       "      <td>0.437563</td>\n",
       "      <td>2.806237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>-0.554853</td>\n",
       "      <td>0.925850</td>\n",
       "      <td>1.073921</td>\n",
       "      <td>-1.481288</td>\n",
       "      <td>-0.755573</td>\n",
       "      <td>1.714846</td>\n",
       "      <td>0.175056</td>\n",
       "      <td>1.240910</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399079</th>\n",
       "      <td>-1.073041</td>\n",
       "      <td>-1.985104</td>\n",
       "      <td>0.711292</td>\n",
       "      <td>-0.409493</td>\n",
       "      <td>-0.391896</td>\n",
       "      <td>2.028145</td>\n",
       "      <td>-0.354190</td>\n",
       "      <td>-4.799469</td>\n",
       "      <td>-0.724986</td>\n",
       "      <td>2.122654</td>\n",
       "      <td>...</td>\n",
       "      <td>1.463212</td>\n",
       "      <td>-0.215956</td>\n",
       "      <td>-0.587354</td>\n",
       "      <td>1.814109</td>\n",
       "      <td>2.096471</td>\n",
       "      <td>-0.890198</td>\n",
       "      <td>3.866669</td>\n",
       "      <td>1.076269</td>\n",
       "      <td>1.044740</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399115</th>\n",
       "      <td>-0.750507</td>\n",
       "      <td>0.077556</td>\n",
       "      <td>-0.189132</td>\n",
       "      <td>-0.509335</td>\n",
       "      <td>0.152268</td>\n",
       "      <td>1.351847</td>\n",
       "      <td>-0.225641</td>\n",
       "      <td>-0.593324</td>\n",
       "      <td>0.359630</td>\n",
       "      <td>1.465795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211838</td>\n",
       "      <td>-0.462109</td>\n",
       "      <td>-0.663366</td>\n",
       "      <td>-0.166433</td>\n",
       "      <td>-0.298871</td>\n",
       "      <td>-0.248243</td>\n",
       "      <td>-0.266417</td>\n",
       "      <td>-0.039466</td>\n",
       "      <td>0.183937</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399221</th>\n",
       "      <td>-0.956475</td>\n",
       "      <td>-0.260599</td>\n",
       "      <td>-0.477419</td>\n",
       "      <td>-0.725376</td>\n",
       "      <td>0.220927</td>\n",
       "      <td>1.150903</td>\n",
       "      <td>-0.215788</td>\n",
       "      <td>-0.271085</td>\n",
       "      <td>0.116082</td>\n",
       "      <td>0.937208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177100</td>\n",
       "      <td>-0.821845</td>\n",
       "      <td>-0.640879</td>\n",
       "      <td>0.323626</td>\n",
       "      <td>-0.623795</td>\n",
       "      <td>0.305388</td>\n",
       "      <td>0.220368</td>\n",
       "      <td>0.417024</td>\n",
       "      <td>0.081399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399347</th>\n",
       "      <td>-2.032157</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>-0.682422</td>\n",
       "      <td>0.574182</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>-0.653287</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>-1.703599</td>\n",
       "      <td>-0.086172</td>\n",
       "      <td>1.116697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196534</td>\n",
       "      <td>-0.431074</td>\n",
       "      <td>-0.043430</td>\n",
       "      <td>0.638944</td>\n",
       "      <td>0.708614</td>\n",
       "      <td>-0.265638</td>\n",
       "      <td>2.000774</td>\n",
       "      <td>-0.309918</td>\n",
       "      <td>0.039013</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399412</th>\n",
       "      <td>-0.656023</td>\n",
       "      <td>-0.436416</td>\n",
       "      <td>-0.964362</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>-0.556421</td>\n",
       "      <td>1.137871</td>\n",
       "      <td>0.833169</td>\n",
       "      <td>-1.106546</td>\n",
       "      <td>0.646703</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344981</td>\n",
       "      <td>-0.898732</td>\n",
       "      <td>-1.407385</td>\n",
       "      <td>0.901137</td>\n",
       "      <td>0.884053</td>\n",
       "      <td>-0.075523</td>\n",
       "      <td>0.520995</td>\n",
       "      <td>0.305606</td>\n",
       "      <td>0.991070</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399439</th>\n",
       "      <td>-3.484410</td>\n",
       "      <td>0.198731</td>\n",
       "      <td>-2.275734</td>\n",
       "      <td>1.600426</td>\n",
       "      <td>-0.602113</td>\n",
       "      <td>0.570862</td>\n",
       "      <td>-2.459639</td>\n",
       "      <td>-1.793852</td>\n",
       "      <td>0.520265</td>\n",
       "      <td>2.437524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519607</td>\n",
       "      <td>1.254383</td>\n",
       "      <td>0.381930</td>\n",
       "      <td>0.107412</td>\n",
       "      <td>-0.625359</td>\n",
       "      <td>-1.149893</td>\n",
       "      <td>4.463324</td>\n",
       "      <td>-1.747980</td>\n",
       "      <td>1.103908</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399486</th>\n",
       "      <td>-2.174315</td>\n",
       "      <td>-0.771134</td>\n",
       "      <td>-0.219296</td>\n",
       "      <td>0.658201</td>\n",
       "      <td>-0.466763</td>\n",
       "      <td>1.532223</td>\n",
       "      <td>-1.282034</td>\n",
       "      <td>-0.796695</td>\n",
       "      <td>0.226195</td>\n",
       "      <td>0.657065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.564221</td>\n",
       "      <td>-0.853640</td>\n",
       "      <td>-0.025189</td>\n",
       "      <td>0.322730</td>\n",
       "      <td>0.779228</td>\n",
       "      <td>-1.343147</td>\n",
       "      <td>0.630171</td>\n",
       "      <td>0.874886</td>\n",
       "      <td>0.934839</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399528</th>\n",
       "      <td>-1.708860</td>\n",
       "      <td>0.620446</td>\n",
       "      <td>-1.332866</td>\n",
       "      <td>0.093222</td>\n",
       "      <td>-1.786252</td>\n",
       "      <td>0.750872</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>-1.023834</td>\n",
       "      <td>-0.421181</td>\n",
       "      <td>-0.120476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408251</td>\n",
       "      <td>0.241024</td>\n",
       "      <td>0.508140</td>\n",
       "      <td>0.304286</td>\n",
       "      <td>1.154832</td>\n",
       "      <td>0.189594</td>\n",
       "      <td>0.868491</td>\n",
       "      <td>-0.191355</td>\n",
       "      <td>1.425662</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399620</th>\n",
       "      <td>-2.855734</td>\n",
       "      <td>-0.028074</td>\n",
       "      <td>-2.065748</td>\n",
       "      <td>1.171286</td>\n",
       "      <td>-0.710276</td>\n",
       "      <td>0.505190</td>\n",
       "      <td>-2.139056</td>\n",
       "      <td>-2.136398</td>\n",
       "      <td>0.856955</td>\n",
       "      <td>1.965124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030482</td>\n",
       "      <td>1.719702</td>\n",
       "      <td>0.245160</td>\n",
       "      <td>-0.045007</td>\n",
       "      <td>-0.729646</td>\n",
       "      <td>-1.236718</td>\n",
       "      <td>3.835647</td>\n",
       "      <td>-1.975219</td>\n",
       "      <td>0.831796</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399644</th>\n",
       "      <td>-1.068534</td>\n",
       "      <td>-3.462094</td>\n",
       "      <td>0.050120</td>\n",
       "      <td>0.713514</td>\n",
       "      <td>-0.137569</td>\n",
       "      <td>1.501223</td>\n",
       "      <td>1.208010</td>\n",
       "      <td>0.144215</td>\n",
       "      <td>-0.086929</td>\n",
       "      <td>0.847600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.204220</td>\n",
       "      <td>-2.125882</td>\n",
       "      <td>-0.503811</td>\n",
       "      <td>0.396887</td>\n",
       "      <td>0.940009</td>\n",
       "      <td>-0.212489</td>\n",
       "      <td>1.497870</td>\n",
       "      <td>0.750555</td>\n",
       "      <td>-0.077648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399663</th>\n",
       "      <td>-2.194664</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>-0.399838</td>\n",
       "      <td>0.323898</td>\n",
       "      <td>0.294063</td>\n",
       "      <td>0.042186</td>\n",
       "      <td>-0.884521</td>\n",
       "      <td>-1.749098</td>\n",
       "      <td>0.864304</td>\n",
       "      <td>1.352624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254295</td>\n",
       "      <td>0.234668</td>\n",
       "      <td>0.101279</td>\n",
       "      <td>0.240944</td>\n",
       "      <td>-0.336801</td>\n",
       "      <td>-0.815096</td>\n",
       "      <td>2.181824</td>\n",
       "      <td>-0.757237</td>\n",
       "      <td>0.310407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399668</th>\n",
       "      <td>-0.647922</td>\n",
       "      <td>-0.486316</td>\n",
       "      <td>0.560183</td>\n",
       "      <td>0.546804</td>\n",
       "      <td>0.164426</td>\n",
       "      <td>0.808198</td>\n",
       "      <td>-0.922396</td>\n",
       "      <td>-0.691680</td>\n",
       "      <td>0.622662</td>\n",
       "      <td>0.463742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052657</td>\n",
       "      <td>-0.527012</td>\n",
       "      <td>-0.653689</td>\n",
       "      <td>-0.132525</td>\n",
       "      <td>-0.797734</td>\n",
       "      <td>-0.867754</td>\n",
       "      <td>0.539548</td>\n",
       "      <td>0.072349</td>\n",
       "      <td>0.821046</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399733</th>\n",
       "      <td>-1.175050</td>\n",
       "      <td>0.834477</td>\n",
       "      <td>-1.766495</td>\n",
       "      <td>2.480930</td>\n",
       "      <td>-0.936974</td>\n",
       "      <td>0.601877</td>\n",
       "      <td>-2.919344</td>\n",
       "      <td>-4.013079</td>\n",
       "      <td>-1.480687</td>\n",
       "      <td>-2.273367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766808</td>\n",
       "      <td>-1.626861</td>\n",
       "      <td>-1.466143</td>\n",
       "      <td>3.123789</td>\n",
       "      <td>1.268822</td>\n",
       "      <td>-2.930246</td>\n",
       "      <td>3.916485</td>\n",
       "      <td>-2.425346</td>\n",
       "      <td>2.562204</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399786</th>\n",
       "      <td>-3.295932</td>\n",
       "      <td>-3.147943</td>\n",
       "      <td>-3.353554</td>\n",
       "      <td>-0.218314</td>\n",
       "      <td>-0.764021</td>\n",
       "      <td>2.056453</td>\n",
       "      <td>-2.396558</td>\n",
       "      <td>-3.326715</td>\n",
       "      <td>0.131635</td>\n",
       "      <td>1.419867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163907</td>\n",
       "      <td>-0.751885</td>\n",
       "      <td>-0.106158</td>\n",
       "      <td>3.022256</td>\n",
       "      <td>-0.470503</td>\n",
       "      <td>-1.517110</td>\n",
       "      <td>4.511029</td>\n",
       "      <td>-0.919953</td>\n",
       "      <td>3.479200</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399839</th>\n",
       "      <td>-0.476576</td>\n",
       "      <td>-0.397057</td>\n",
       "      <td>0.090555</td>\n",
       "      <td>-0.610979</td>\n",
       "      <td>-0.649564</td>\n",
       "      <td>0.797627</td>\n",
       "      <td>-0.237605</td>\n",
       "      <td>-0.144004</td>\n",
       "      <td>0.198561</td>\n",
       "      <td>-0.219684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049980</td>\n",
       "      <td>-0.134842</td>\n",
       "      <td>-0.768386</td>\n",
       "      <td>0.559454</td>\n",
       "      <td>0.688374</td>\n",
       "      <td>-0.060378</td>\n",
       "      <td>0.520389</td>\n",
       "      <td>0.339987</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399884</th>\n",
       "      <td>-1.147376</td>\n",
       "      <td>-0.621283</td>\n",
       "      <td>-0.242307</td>\n",
       "      <td>-0.201828</td>\n",
       "      <td>-0.048713</td>\n",
       "      <td>2.284078</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>-0.261334</td>\n",
       "      <td>0.293938</td>\n",
       "      <td>1.555631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370509</td>\n",
       "      <td>-1.090771</td>\n",
       "      <td>-1.886965</td>\n",
       "      <td>1.141032</td>\n",
       "      <td>-0.360937</td>\n",
       "      <td>0.658872</td>\n",
       "      <td>0.437058</td>\n",
       "      <td>0.381055</td>\n",
       "      <td>1.031932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399943</th>\n",
       "      <td>-2.459647</td>\n",
       "      <td>-1.060419</td>\n",
       "      <td>-1.198154</td>\n",
       "      <td>0.497662</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>-0.557055</td>\n",
       "      <td>-1.503202</td>\n",
       "      <td>-1.114074</td>\n",
       "      <td>0.896622</td>\n",
       "      <td>1.340464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519407</td>\n",
       "      <td>0.097472</td>\n",
       "      <td>-0.478527</td>\n",
       "      <td>1.122672</td>\n",
       "      <td>-0.826794</td>\n",
       "      <td>-0.626696</td>\n",
       "      <td>2.460681</td>\n",
       "      <td>-0.775669</td>\n",
       "      <td>0.523265</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399977</th>\n",
       "      <td>-2.666909</td>\n",
       "      <td>0.075190</td>\n",
       "      <td>-0.614091</td>\n",
       "      <td>0.103249</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>-0.103826</td>\n",
       "      <td>-1.072121</td>\n",
       "      <td>-1.979452</td>\n",
       "      <td>1.240583</td>\n",
       "      <td>1.813867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>0.203405</td>\n",
       "      <td>0.139926</td>\n",
       "      <td>1.170154</td>\n",
       "      <td>0.387958</td>\n",
       "      <td>-1.181209</td>\n",
       "      <td>2.705708</td>\n",
       "      <td>-0.510242</td>\n",
       "      <td>0.208977</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8230 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "67     -1.049690 -0.771513  0.158670 -0.312674 -0.377480 -0.369302  0.280022   \n",
       "236    -2.478013 -0.043695  0.771950 -2.139385  1.071926  3.770401  0.168407   \n",
       "243    -1.255681 -0.777635 -0.877367 -0.462382 -0.081313 -0.237224 -0.003204   \n",
       "249    -2.253641 -1.181772 -1.492457  0.818130 -0.904294  1.049954 -0.735170   \n",
       "253    -1.196334 -0.028245 -0.396672 -0.385498 -0.167445  0.282152  0.353004   \n",
       "371    -0.257420 -0.445647 -0.404965  0.293855  0.203597  1.385421  0.550570   \n",
       "386    -3.743620 -1.367480 -2.360441  0.530165  1.211634 -0.313798 -2.481249   \n",
       "460    -2.728978 -1.179033 -2.405885 -0.344301  0.077061  0.022148 -1.370032   \n",
       "506    -2.849284 -0.879398 -1.815585  0.139728 -0.131045  0.958549  0.816506   \n",
       "636    -4.064809 -1.815839  0.205814  2.079911 -1.302466  1.661439 -1.536190   \n",
       "696    -1.049337 -0.034050 -0.946103 -0.727392 -1.949147  0.593835 -0.335773   \n",
       "825    -2.113971 -0.149115 -0.425182  0.728214  0.260170  0.096754 -1.521641   \n",
       "844    -1.175175 -0.876603 -1.170906 -0.997286 -0.748919 -0.168592 -0.450506   \n",
       "905    -2.025106  0.395679 -2.377700  1.719629 -1.537529  0.887685 -2.255765   \n",
       "951    -1.988590  0.272053 -1.480868  0.399932 -1.882465  0.152145  0.137399   \n",
       "1033   -5.887641 -1.946310  2.034301 -0.684665 -0.648630 -0.100018 -1.938350   \n",
       "1056   -1.042665  0.109254 -0.151601 -0.647027  0.780285  1.541363  0.353203   \n",
       "1108   -1.962819 -1.026993 -1.287164 -1.371570  0.844003  1.967685 -0.803276   \n",
       "1163   -0.135766 -2.134075 -0.916568  0.936112 -0.238095  0.958329  0.601731   \n",
       "1239   -0.793785  0.024350 -0.102379 -0.789162  0.067272  1.630809 -0.418927   \n",
       "1269   -3.384265 -2.492061 -1.038584 -0.300156  0.093111 -0.100909  0.261836   \n",
       "1311   -0.301632 -0.318571 -0.436904 -0.311855 -0.208266  0.501674 -0.294672   \n",
       "1340   -0.301632 -0.318571 -0.436904 -0.311855 -0.208266  0.501674 -0.294672   \n",
       "1369   -1.432631 -0.244971 -0.686108 -0.244268  0.034909  1.100058 -0.239596   \n",
       "1391   -2.784023 -5.867600 -0.891076  4.803305  0.676565  3.405698  0.064993   \n",
       "1405   -0.859272 -0.592162 -0.538060 -0.909108 -0.054383  1.126245  0.389288   \n",
       "1409   -2.032157  0.055885 -0.682422  0.574182  0.059704 -0.653287  0.008511   \n",
       "1411   -0.649767 -0.912867 -0.961072  0.227151 -0.937122 -0.122507  0.068271   \n",
       "1418   -2.176965 -0.810508 -1.050303  0.017479 -0.052324  0.136931 -1.237619   \n",
       "1546   -0.679589 -0.219330  0.032546 -0.569294 -0.937822  1.248770 -0.672257   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "398725 -1.146187 -1.425933 -0.508930  0.611420  0.167838  0.970509 -0.819843   \n",
       "398733 -1.735178  1.195967 -1.600164 -0.151935 -2.318790  1.312073  1.100908   \n",
       "398763 -1.217626  0.201986 -0.688823 -1.219053  0.643099  3.286798  0.077760   \n",
       "398768 -1.049690 -0.771513  0.158670 -0.312674 -0.377480 -0.369302  0.280022   \n",
       "398853 -0.257710 -0.017807 -0.004450 -0.243110  0.298243  0.751885  0.021078   \n",
       "398866 -0.704512 -0.272402 -0.398904 -0.257414 -1.266904  0.741954  0.472652   \n",
       "398910 -0.750507  0.077556 -0.189132 -0.509335  0.152268  1.351847 -0.225641   \n",
       "398993 -0.257420 -0.445647 -0.404965  0.293855  0.203597  1.385421  0.550570   \n",
       "399002 -0.959470 -0.552836 -0.915317  0.131137 -0.527347  0.085283 -0.116752   \n",
       "399034  0.293867  0.383818 -0.598053  2.049648 -1.057692 -1.063475 -1.151902   \n",
       "399051 -0.695505 -0.612101  0.031835 -0.371482 -0.028178  0.359439  0.746080   \n",
       "399055 -2.111944 -0.765627 -1.180691  0.108773 -0.963621  0.241166 -1.957313   \n",
       "399079 -1.073041 -1.985104  0.711292 -0.409493 -0.391896  2.028145 -0.354190   \n",
       "399115 -0.750507  0.077556 -0.189132 -0.509335  0.152268  1.351847 -0.225641   \n",
       "399221 -0.956475 -0.260599 -0.477419 -0.725376  0.220927  1.150903 -0.215788   \n",
       "399347 -2.032157  0.055885 -0.682422  0.574182  0.059704 -0.653287  0.008511   \n",
       "399412 -0.656023 -0.436416 -0.964362  0.039065 -0.556421  1.137871  0.833169   \n",
       "399439 -3.484410  0.198731 -2.275734  1.600426 -0.602113  0.570862 -2.459639   \n",
       "399486 -2.174315 -0.771134 -0.219296  0.658201 -0.466763  1.532223 -1.282034   \n",
       "399528 -1.708860  0.620446 -1.332866  0.093222 -1.786252  0.750872  0.239865   \n",
       "399620 -2.855734 -0.028074 -2.065748  1.171286 -0.710276  0.505190 -2.139056   \n",
       "399644 -1.068534 -3.462094  0.050120  0.713514 -0.137569  1.501223  1.208010   \n",
       "399663 -2.194664  0.169300 -0.399838  0.323898  0.294063  0.042186 -0.884521   \n",
       "399668 -0.647922 -0.486316  0.560183  0.546804  0.164426  0.808198 -0.922396   \n",
       "399733 -1.175050  0.834477 -1.766495  2.480930 -0.936974  0.601877 -2.919344   \n",
       "399786 -3.295932 -3.147943 -3.353554 -0.218314 -0.764021  2.056453 -2.396558   \n",
       "399839 -0.476576 -0.397057  0.090555 -0.610979 -0.649564  0.797627 -0.237605   \n",
       "399884 -1.147376 -0.621283 -0.242307 -0.201828 -0.048713  2.284078  0.007582   \n",
       "399943 -2.459647 -1.060419 -1.198154  0.497662 -0.121336 -0.557055 -1.503202   \n",
       "399977 -2.666909  0.075190 -0.614091  0.103249  0.009908 -0.103826 -1.072121   \n",
       "\n",
       "               7         8         9   ...          91        92        93  \\\n",
       "67      0.023114 -0.913724  0.979315   ...    0.280885  1.201361  0.932319   \n",
       "236    -2.631820  0.614697  2.824265   ...   -0.973839 -1.481487 -1.533303   \n",
       "243    -0.343707  0.083085  1.299823   ...    0.153772  0.059088  0.626004   \n",
       "249     1.372616  0.335229  1.417195   ...   -0.478855 -0.081880  0.218353   \n",
       "253    -1.122284  0.082020  0.774006   ...    0.719216 -0.064531 -0.269396   \n",
       "371     0.094740  0.229750  0.888640   ...   -0.231441 -0.762304 -0.827463   \n",
       "386    -3.569509  0.605719  2.864000   ...    0.767673  1.146606  1.577477   \n",
       "460    -2.781253  0.605790  2.134533   ...    1.082223  1.320488  0.638416   \n",
       "506    -0.050087 -1.026676  1.160616   ...    0.551300  0.738908 -1.800838   \n",
       "636    -0.972196 -1.475644  1.063404   ...   -1.979713 -1.056393  0.377808   \n",
       "696    -3.115400 -2.332368  1.797949   ...   -0.050593 -1.129677  1.237034   \n",
       "825    -2.434401  0.862704  1.843156   ...    0.098151 -0.121465  0.680853   \n",
       "844    -0.319784  0.041448  2.472831   ...    0.316502 -0.904556  1.267430   \n",
       "905    -1.024681  2.091985  2.069914   ...   -3.952944 -2.167449 -0.821809   \n",
       "951    -1.603543 -1.241909  0.522514   ...    0.393627 -1.027048  1.318500   \n",
       "1033   -1.899691 -0.989534  3.401803   ...    2.511203 -2.588614 -3.134518   \n",
       "1056   -1.391314  0.398150  1.228879   ...   -0.414465 -0.345195 -1.032897   \n",
       "1108   -1.455131  0.405860  1.316828   ...   -0.522909 -1.431578 -0.945789   \n",
       "1163    0.508158 -0.084861  0.039660   ...    0.110006 -1.141496  0.489964   \n",
       "1239   -0.691452  0.724723  2.145714   ...   -0.513361 -0.637113 -1.111747   \n",
       "1269   -2.989679 -1.269629  0.222143   ...    0.596686  1.121777  0.569784   \n",
       "1311   -0.059025  0.066760 -0.185457   ...   -0.161395 -0.399576  0.200129   \n",
       "1340   -0.059025  0.066760 -0.185457   ...   -0.161395 -0.399576  0.200129   \n",
       "1369   -0.583594 -0.181081  1.401062   ...    0.187933 -1.366067 -0.950168   \n",
       "1391    0.627836  0.956686  1.186856   ...   -1.492768 -4.440834  0.329444   \n",
       "1405   -0.898213 -0.332280  0.187639   ...   -0.547992 -0.564989 -0.865920   \n",
       "1409   -1.703599 -0.086172  1.116697   ...   -0.196534 -0.431074 -0.043430   \n",
       "1411   -0.622851 -0.314905  1.006329   ...   -0.150122 -0.174207  1.061313   \n",
       "1418   -1.505365  0.237543  1.966551   ...   -0.020130  0.425620  0.542820   \n",
       "1546   -0.345671  0.350842 -0.187192   ...    0.205031 -0.267118 -0.613532   \n",
       "...          ...       ...       ...   ...         ...       ...       ...   \n",
       "398725 -0.790625 -0.168435  0.426074   ...   -0.004054 -0.051900 -0.441303   \n",
       "398733 -1.008126 -0.958141  0.082558   ...   -0.802012 -0.692856  0.570078   \n",
       "398763 -1.470432  0.746922  2.925592   ...   -0.319505 -0.035759 -1.320024   \n",
       "398768  0.023114 -0.913724  0.979315   ...    0.280885  1.201361  0.932319   \n",
       "398853 -0.364747  0.115877  0.448329   ...   -0.048217 -0.216032 -0.310807   \n",
       "398866  0.283822 -0.182845  0.473933   ...    0.437301 -0.063556  0.083362   \n",
       "398910 -0.593324  0.359630  1.465795   ...   -0.211838 -0.462109 -0.663366   \n",
       "398993  0.094740  0.229750  0.888640   ...   -0.231441 -0.762304 -0.827463   \n",
       "399002 -0.548992 -0.213859  0.853386   ...    0.003198  0.119292  1.136510   \n",
       "399034 -0.922707 -1.129242 -0.733469   ...   -0.233165 -1.369149 -1.223982   \n",
       "399051 -1.075386  0.128655  0.435903   ...    0.304475 -0.285431 -0.333920   \n",
       "399055 -1.676918  0.437563  2.806237   ...    0.259800 -0.554853  0.925850   \n",
       "399079 -4.799469 -0.724986  2.122654   ...    1.463212 -0.215956 -0.587354   \n",
       "399115 -0.593324  0.359630  1.465795   ...   -0.211838 -0.462109 -0.663366   \n",
       "399221 -0.271085  0.116082  0.937208   ...   -0.177100 -0.821845 -0.640879   \n",
       "399347 -1.703599 -0.086172  1.116697   ...   -0.196534 -0.431074 -0.043430   \n",
       "399412 -1.106546  0.646703  0.102273   ...   -0.344981 -0.898732 -1.407385   \n",
       "399439 -1.793852  0.520265  2.437524   ...    0.519607  1.254383  0.381930   \n",
       "399486 -0.796695  0.226195  0.657065   ...   -0.564221 -0.853640 -0.025189   \n",
       "399528 -1.023834 -0.421181 -0.120476   ...    0.408251  0.241024  0.508140   \n",
       "399620 -2.136398  0.856955  1.965124   ...   -0.030482  1.719702  0.245160   \n",
       "399644  0.144215 -0.086929  0.847600   ...    1.204220 -2.125882 -0.503811   \n",
       "399663 -1.749098  0.864304  1.352624   ...    0.254295  0.234668  0.101279   \n",
       "399668 -0.691680  0.622662  0.463742   ...   -0.052657 -0.527012 -0.653689   \n",
       "399733 -4.013079 -1.480687 -2.273367   ...   -0.766808 -1.626861 -1.466143   \n",
       "399786 -3.326715  0.131635  1.419867   ...   -0.163907 -0.751885 -0.106158   \n",
       "399839 -0.144004  0.198561 -0.219684   ...    0.049980 -0.134842 -0.768386   \n",
       "399884 -0.261334  0.293938  1.555631   ...   -0.370509 -1.090771 -1.886965   \n",
       "399943 -1.114074  0.896622  1.340464   ...    0.519407  0.097472 -0.478527   \n",
       "399977 -1.979452  1.240583  1.813867   ...    0.217408  0.203405  0.139926   \n",
       "\n",
       "              94        95        96        97        98        99  Labels  \n",
       "67      1.638536  0.913610  0.610413  0.355339 -0.137420  0.647466       5  \n",
       "236     0.760727 -1.990130  0.780788  0.430325  1.497166  0.265564       2  \n",
       "243     0.983645  0.570106 -0.825074  1.247822  0.274666  0.839839       5  \n",
       "249     1.944819  0.459990 -1.591547  1.275095 -0.146483  0.567948       5  \n",
       "253     0.155455  0.313454  0.991185  0.885388  1.073633  0.327812       3  \n",
       "371     0.031347  0.141893 -0.036272  0.270480  0.416600 -0.195311       2  \n",
       "386     1.893352 -0.035766 -1.228378  4.257276 -0.839938  1.080752       5  \n",
       "460     1.844516 -0.514469 -0.896418  4.258131 -0.478206  0.798461       5  \n",
       "506    -0.707670  1.204473  1.884565  1.121318  0.464986  1.230489       2  \n",
       "636     1.726000  3.398573 -2.573513  0.981770  0.667107  0.868972       5  \n",
       "696     0.911729  0.794443 -0.850870  2.168645 -0.224972  2.464960       8  \n",
       "825     0.308391 -0.376037 -1.516559  3.123985 -0.650126  0.258620       5  \n",
       "844     1.378718  0.303729 -0.875339  2.233519  0.477678  1.549089       5  \n",
       "905    -0.893908  0.392775 -0.435671  1.102706  3.499334  4.208037      11  \n",
       "951     0.524059  1.555427  0.041495  1.978925 -0.427646  2.253969       5  \n",
       "1033    1.402726 -0.007625  1.710679  0.138814  0.775336  0.300810       2  \n",
       "1056   -0.343206 -0.863417 -0.467653  0.086490  0.130265  0.459209       2  \n",
       "1108    1.212372 -1.319644 -0.035256  1.272448  0.664281  1.198406       2  \n",
       "1163    0.867882  0.920993 -0.280907  1.083940  1.092334  0.416514       2  \n",
       "1239    0.277987 -0.594351 -0.152484 -0.222506  0.422848  0.361659       2  \n",
       "1269    0.980308  0.805499 -0.906797  3.203183 -0.313417  1.292847      10  \n",
       "1311    0.381431  1.089576 -0.026140  1.146891 -0.080369  0.501096       5  \n",
       "1340    0.381431  1.089576 -0.026140  1.146891 -0.080369  0.501096       5  \n",
       "1369    0.080710 -1.656925 -0.077629  0.927300  0.648066  0.792139       2  \n",
       "1391   -0.305374  5.432211  4.376016  4.416584  1.141813  3.076368       2  \n",
       "1405    0.988506  0.642486 -0.108232  0.703986  0.139774  1.114346       3  \n",
       "1409    0.638944  0.708614 -0.265638  2.000774 -0.309918  0.039013       5  \n",
       "1411    0.412757  0.808535 -0.309061  0.254641  0.762193  0.656666       5  \n",
       "1418    1.081372 -0.592904 -0.874931  1.129879 -0.616982  0.815303       5  \n",
       "1546    0.663867  0.974826  0.223761  0.382849  0.180882  0.238202       3  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "398725  0.785960  0.177157 -0.982575  0.710367  0.949398 -0.029121      10  \n",
       "398733  1.033969  1.572861  0.630344  2.433918 -0.498809  0.975340       5  \n",
       "398763 -0.156371 -1.578767 -0.000656  0.031791 -0.597357  1.640970       2  \n",
       "398768  1.638536  0.913610  0.610413  0.355339 -0.137420  0.647466       5  \n",
       "398853 -0.009107 -0.284626 -0.012712 -0.260300  0.210753 -0.074270       2  \n",
       "398866 -0.413158  0.562542  0.420663  0.204915  0.469280  0.647910       5  \n",
       "398910 -0.166433 -0.298871 -0.248243 -0.266417 -0.039466  0.183937       2  \n",
       "398993  0.031347  0.141893 -0.036272  0.270480  0.416600 -0.195311       2  \n",
       "399002 -0.170949  1.284367  0.112111  0.887319  0.301567  0.807245       5  \n",
       "399034  1.707901  1.303650 -0.742352  2.671120 -0.675203  1.476823       6  \n",
       "399051  0.807024  0.268054  0.296205  0.357785  0.633814  0.447008       3  \n",
       "399055  1.073921 -1.481288 -0.755573  1.714846  0.175056  1.240910       5  \n",
       "399079  1.814109  2.096471 -0.890198  3.866669  1.076269  1.044740      10  \n",
       "399115 -0.166433 -0.298871 -0.248243 -0.266417 -0.039466  0.183937       2  \n",
       "399221  0.323626 -0.623795  0.305388  0.220368  0.417024  0.081399       2  \n",
       "399347  0.638944  0.708614 -0.265638  2.000774 -0.309918  0.039013       5  \n",
       "399412  0.901137  0.884053 -0.075523  0.520995  0.305606  0.991070       3  \n",
       "399439  0.107412 -0.625359 -1.149893  4.463324 -1.747980  1.103908       5  \n",
       "399486  0.322730  0.779228 -1.343147  0.630171  0.874886  0.934839       5  \n",
       "399528  0.304286  1.154832  0.189594  0.868491 -0.191355  1.425662       5  \n",
       "399620 -0.045007 -0.729646 -1.236718  3.835647 -1.975219  0.831796       5  \n",
       "399644  0.396887  0.940009 -0.212489  1.497870  0.750555 -0.077648       2  \n",
       "399663  0.240944 -0.336801 -0.815096  2.181824 -0.757237  0.310407       5  \n",
       "399668 -0.132525 -0.797734 -0.867754  0.539548  0.072349  0.821046      18  \n",
       "399733  3.123789  1.268822 -2.930246  3.916485 -2.425346  2.562204       6  \n",
       "399786  3.022256 -0.470503 -1.517110  4.511029 -0.919953  3.479200       5  \n",
       "399839  0.559454  0.688374 -0.060378  0.520389  0.339987  0.360903       3  \n",
       "399884  1.141032 -0.360937  0.658872  0.437058  0.381055  1.031932       2  \n",
       "399943  1.122672 -0.826794 -0.626696  2.460681 -0.775669  0.523265       5  \n",
       "399977  1.170154  0.387958 -1.181209  2.705708 -0.510242  0.208977       5  \n",
       "\n",
       "[8230 rows x 101 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_dataset.loc[additional_dataset[\"Labels\"]!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_truth=[np.argmax(value) for value in validation_labels]\n",
    "nn_y_pred=[np.argmax(value) for value in model_1.predict(validation_features_1)]\n",
    "print(\"Validation Accuracy : {}\".format(accuracy(nn_y_pred,nn_y_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(\"level1_semsup_1.h5\")\n",
    "model_2.save(\"level1_semsup_2.h5\")\n",
    "model_3.save(\"level1_semsup_3.h5\")\n",
    "model_4.save(\"level1_semsup_4.h5\")\n",
    "model_5.save(\"level1_semsup_5.h5\")\n",
    "model_6.save(\"level1_semsup_6.h5\")\n",
    "model_7.save(\"level1_semsup_7.h5\")\n",
    "model_8.save(\"level1_semsup_8.h5\")\n",
    "model_9.save(\"level1_semsup_9.h5\")\n",
    "model_10.save(\"level1_semsup_10.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
