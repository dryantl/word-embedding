{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Embedder\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.grid_search import GridSearchCV as GS\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures as Poly\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Model's File Location\n",
    "\n",
    "version = \"version_4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_pipeline import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/{}/word_embedder.pickle\".format(version), \"rb\") as file:\n",
    "    word_embedder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<preprocessing_pipeline.preprocessing at 0xee69d3d128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.fasttext.FastText at 0xee69d3d2e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data To Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data untuk klasifikasi kategori produk\n",
    "data_for_classification=pd.read_csv(\"data/product_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Id</th>\n",
       "      <th>Category Id</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Product Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114628582</td>\n",
       "      <td>2</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>PC HP Pavillion 251VGA-i5(4460) with LED-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640569762</td>\n",
       "      <td>2</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Unik SanDisk Flashdisk 64GB Ultra USB 3 3 0 Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>757005547</td>\n",
       "      <td>2</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Paket Spek PC Agan Bagas 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>758393462</td>\n",
       "      <td>2</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>PAket Spek PC Agan JP Wogo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>757008997</td>\n",
       "      <td>2</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>PC HP All In One AIO 20 C303D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product Id  Category Id Category Name  \\\n",
       "0   114628582            2       Desktop   \n",
       "1   640569762            2       Desktop   \n",
       "2   757005547            2       Desktop   \n",
       "3   758393462            2       Desktop   \n",
       "4   757008997            2       Desktop   \n",
       "\n",
       "                                       Product Title  \n",
       "0       PC HP Pavillion 251VGA-i5(4460) with LED-20   \n",
       "1  Unik SanDisk Flashdisk 64GB Ultra USB 3 3 0 Fl...  \n",
       "2                         Paket Spek PC Agan Bagas 2  \n",
       "3                         PAket Spek PC Agan JP Wogo  \n",
       "4                      PC HP All In One AIO 20 C303D  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_classification.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 400000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_for_classification=pd.read_csv(\"data/big.csv\",header=None)\n",
    "large_data_for_classification.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hardware</td>\n",
       "      <td>KINGSTON+KVR1333D3N9</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musik</td>\n",
       "      <td>power+amplifier+wisdom+</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outwear-motor</td>\n",
       "      <td>jas%20hujan%20anak</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>celana</td>\n",
       "      <td>Celana+bahan+formal</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komputer</td>\n",
       "      <td>Preset+lightroom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                        1       2\n",
       "0       hardware     KINGSTON+KVR1333D3N9  1510.0\n",
       "1          musik  power+amplifier+wisdom+    62.0\n",
       "2  outwear-motor       jas%20hujan%20anak   391.0\n",
       "3         celana      Celana+bahan+formal   288.0\n",
       "4       komputer         Preset+lightroom     1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data_for_classification.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess product title to 100-dimensional vector\n",
    "#and preprocess category name to integer label\n",
    "large_embedded_data, large_label_encoder = preprocessor.preprocess_data(\n",
    "    large_data_for_classification[1],\n",
    "    large_data_for_classification[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.275295</td>\n",
       "      <td>-0.438877</td>\n",
       "      <td>0.347446</td>\n",
       "      <td>0.420617</td>\n",
       "      <td>-0.655826</td>\n",
       "      <td>-0.893736</td>\n",
       "      <td>-0.268864</td>\n",
       "      <td>0.091967</td>\n",
       "      <td>0.253759</td>\n",
       "      <td>-0.407018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060328</td>\n",
       "      <td>0.121378</td>\n",
       "      <td>-0.236838</td>\n",
       "      <td>1.079665</td>\n",
       "      <td>-0.457356</td>\n",
       "      <td>-0.169778</td>\n",
       "      <td>-0.031531</td>\n",
       "      <td>-0.533224</td>\n",
       "      <td>-0.596936</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225148</td>\n",
       "      <td>1.786125</td>\n",
       "      <td>0.616444</td>\n",
       "      <td>-0.040366</td>\n",
       "      <td>-0.316455</td>\n",
       "      <td>0.551794</td>\n",
       "      <td>-0.654612</td>\n",
       "      <td>-0.795263</td>\n",
       "      <td>1.905773</td>\n",
       "      <td>0.121287</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.228765</td>\n",
       "      <td>-0.147218</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>-0.156134</td>\n",
       "      <td>-0.311683</td>\n",
       "      <td>0.178662</td>\n",
       "      <td>0.349768</td>\n",
       "      <td>-0.696280</td>\n",
       "      <td>0.755887</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.227633</td>\n",
       "      <td>-0.858571</td>\n",
       "      <td>-0.520574</td>\n",
       "      <td>0.164235</td>\n",
       "      <td>-2.518956</td>\n",
       "      <td>-0.054563</td>\n",
       "      <td>1.125197</td>\n",
       "      <td>1.010731</td>\n",
       "      <td>0.801415</td>\n",
       "      <td>1.163370</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.043469</td>\n",
       "      <td>2.140666</td>\n",
       "      <td>-2.564406</td>\n",
       "      <td>2.357174</td>\n",
       "      <td>1.715434</td>\n",
       "      <td>-0.115448</td>\n",
       "      <td>-2.115783</td>\n",
       "      <td>-2.267262</td>\n",
       "      <td>-1.784940</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.103322</td>\n",
       "      <td>-0.371176</td>\n",
       "      <td>1.602983</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.338218</td>\n",
       "      <td>-2.489933</td>\n",
       "      <td>-1.299406</td>\n",
       "      <td>1.602620</td>\n",
       "      <td>1.629507</td>\n",
       "      <td>1.238133</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.477074</td>\n",
       "      <td>-2.458070</td>\n",
       "      <td>-1.160693</td>\n",
       "      <td>1.680575</td>\n",
       "      <td>0.541392</td>\n",
       "      <td>1.173590</td>\n",
       "      <td>-2.529253</td>\n",
       "      <td>-1.546401</td>\n",
       "      <td>1.537661</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.096464</td>\n",
       "      <td>-0.166233</td>\n",
       "      <td>0.577785</td>\n",
       "      <td>0.399365</td>\n",
       "      <td>-0.718592</td>\n",
       "      <td>-0.854424</td>\n",
       "      <td>0.374337</td>\n",
       "      <td>-0.318422</td>\n",
       "      <td>-0.018439</td>\n",
       "      <td>0.245501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487409</td>\n",
       "      <td>0.230962</td>\n",
       "      <td>-0.333771</td>\n",
       "      <td>0.158394</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.179707</td>\n",
       "      <td>0.396101</td>\n",
       "      <td>-0.485040</td>\n",
       "      <td>-0.054236</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.275295 -0.438877  0.347446  0.420617 -0.655826 -0.893736 -0.268864   \n",
       "1  0.225148  1.786125  0.616444 -0.040366 -0.316455  0.551794 -0.654612   \n",
       "2  0.227633 -0.858571 -0.520574  0.164235 -2.518956 -0.054563  1.125197   \n",
       "3  1.103322 -0.371176  1.602983  0.019839  0.338218 -2.489933 -1.299406   \n",
       "4 -0.096464 -0.166233  0.577785  0.399365 -0.718592 -0.854424  0.374337   \n",
       "\n",
       "          7         8         9   ...          91        92        93  \\\n",
       "0  0.091967  0.253759 -0.407018   ...    0.060328  0.121378 -0.236838   \n",
       "1 -0.795263  1.905773  0.121287   ...   -2.228765 -0.147218  0.039434   \n",
       "2  1.010731  0.801415  1.163370   ...   -3.043469  2.140666 -2.564406   \n",
       "3  1.602620  1.629507  1.238133   ...   -1.477074 -2.458070 -1.160693   \n",
       "4 -0.318422 -0.018439  0.245501   ...   -0.487409  0.230962 -0.333771   \n",
       "\n",
       "         94        95        96        97        98        99  Labels  \n",
       "0  1.079665 -0.457356 -0.169778 -0.031531 -0.533224 -0.596936      45  \n",
       "1 -0.156134 -0.311683  0.178662  0.349768 -0.696280  0.755887      68  \n",
       "2  2.357174  1.715434 -0.115448 -2.115783 -2.267262 -1.784940      73  \n",
       "3  1.680575  0.541392  1.173590 -2.529253 -1.546401  1.537661      24  \n",
       "4  0.158394  0.055914  0.179707  0.396101 -0.485040 -0.054236      59  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_embedded_data[\"sum\"]=large_embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_embedded_data=large_embedded_data.loc[large_embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392527, 101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/{}/label_encoder.pickle\".format(version), \"wb\") as file:\n",
    "    pickle.dump(large_label_encoder,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=large_embedded_data.copy()\n",
    "sampled_embedded_data=data.sample(n=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_X_train,nn_X_test,nn_y_train,nn_y_test=train_test_split(sampled_embedded_data.drop(\"Labels\",axis=1),to_categorical(sampled_embedded_data[\"Labels\"]),test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "model.add(Dense(1500, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(750, activation='relu'))\n",
    "model.add(Dense(110, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384676 samples, validate on 7851 samples\n",
      "Epoch 1/30\n",
      "384676/384676 [==============================] - 552s 1ms/step - loss: 1.3852 - acc: 0.6539 - val_loss: 1.1321 - val_acc: 0.7000\n",
      "Epoch 2/30\n",
      "384676/384676 [==============================] - 542s 1ms/step - loss: 1.0232 - acc: 0.7250 - val_loss: 1.0331 - val_acc: 0.7267\n",
      "Epoch 3/30\n",
      "384676/384676 [==============================] - 550s 1ms/step - loss: 0.8936 - acc: 0.7526 - val_loss: 0.9892 - val_acc: 0.7386\n",
      "Epoch 4/30\n",
      "384676/384676 [==============================] - 542s 1ms/step - loss: 0.8032 - acc: 0.7721 - val_loss: 0.9470 - val_acc: 0.7459\n",
      "Epoch 5/30\n",
      "384676/384676 [==============================] - 545s 1ms/step - loss: 0.7347 - acc: 0.7859 - val_loss: 0.9328 - val_acc: 0.7542\n",
      "Epoch 6/30\n",
      "384676/384676 [==============================] - 550s 1ms/step - loss: 0.6816 - acc: 0.7965 - val_loss: 0.9135 - val_acc: 0.7574\n",
      "Epoch 7/30\n",
      "384676/384676 [==============================] - 540s 1ms/step - loss: 0.6393 - acc: 0.8055 - val_loss: 0.9053 - val_acc: 0.7633\n",
      "Epoch 8/30\n",
      "384676/384676 [==============================] - 548s 1ms/step - loss: 0.6060 - acc: 0.8117 - val_loss: 0.9026 - val_acc: 0.7644\n",
      "Epoch 9/30\n",
      "384676/384676 [==============================] - 544s 1ms/step - loss: 0.5783 - acc: 0.8164 - val_loss: 0.9107 - val_acc: 0.7670\n",
      "Epoch 10/30\n",
      "384676/384676 [==============================] - 546s 1ms/step - loss: 0.5554 - acc: 0.8206 - val_loss: 0.9157 - val_acc: 0.7675\n",
      "Epoch 11/30\n",
      "384676/384676 [==============================] - 551s 1ms/step - loss: 0.5371 - acc: 0.8240 - val_loss: 0.9091 - val_acc: 0.7693\n",
      "Epoch 12/30\n",
      "384676/384676 [==============================] - 546s 1ms/step - loss: 0.5208 - acc: 0.8269 - val_loss: 0.9229 - val_acc: 0.7677\n",
      "Epoch 13/30\n",
      "384676/384676 [==============================] - 553s 1ms/step - loss: 0.5076 - acc: 0.8289 - val_loss: 0.9206 - val_acc: 0.7742\n",
      "Epoch 14/30\n",
      "384676/384676 [==============================] - 546s 1ms/step - loss: 0.4963 - acc: 0.8308 - val_loss: 0.9300 - val_acc: 0.7687\n",
      "Epoch 15/30\n",
      "384676/384676 [==============================] - 552s 1ms/step - loss: 0.4859 - acc: 0.8329 - val_loss: 0.9374 - val_acc: 0.7724\n",
      "Epoch 16/30\n",
      "384676/384676 [==============================] - 555s 1ms/step - loss: 0.4772 - acc: 0.8344 - val_loss: 0.9384 - val_acc: 0.7756\n",
      "Epoch 17/30\n",
      "384676/384676 [==============================] - 541s 1ms/step - loss: 0.4695 - acc: 0.8356 - val_loss: 0.9395 - val_acc: 0.7721\n",
      "Epoch 18/30\n",
      "384676/384676 [==============================] - 551s 1ms/step - loss: 0.4622 - acc: 0.8362 - val_loss: 0.9443 - val_acc: 0.7770\n",
      "Epoch 19/30\n",
      "384676/384676 [==============================] - 548s 1ms/step - loss: 0.4568 - acc: 0.8372 - val_loss: 0.9574 - val_acc: 0.7737\n",
      "Epoch 20/30\n",
      "384676/384676 [==============================] - 545s 1ms/step - loss: 0.4511 - acc: 0.8378 - val_loss: 0.9603 - val_acc: 0.7715\n",
      "Epoch 21/30\n",
      "384676/384676 [==============================] - 550s 1ms/step - loss: 0.4460 - acc: 0.8388 - val_loss: 0.9639 - val_acc: 0.7748\n",
      "Epoch 22/30\n",
      "384676/384676 [==============================] - 542s 1ms/step - loss: 0.4419 - acc: 0.8395 - val_loss: 0.9670 - val_acc: 0.7772\n",
      "Epoch 23/30\n",
      "  2800/384676 [..............................] - ETA: 9:27 - loss: 0.3866 - acc: 0.8514"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-b417f3684dec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_X_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(nn_X_train, nn_y_train, epochs=30, batch_size=100, validation_data=(nn_X_test,nn_y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_84_77.75.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_inbound_node',\n",
       " '_built',\n",
       " '_check_num_samples',\n",
       " '_check_trainable_weights_consistency',\n",
       " '_container_nodes',\n",
       " '_feed_input_names',\n",
       " '_feed_inputs',\n",
       " '_fit_loop',\n",
       " '_flattened_layers',\n",
       " '_gather_list_attr',\n",
       " '_get_node_attribute_at_index',\n",
       " '_inbound_nodes',\n",
       " '_initial_weights',\n",
       " '_make_predict_function',\n",
       " '_make_test_function',\n",
       " '_make_train_function',\n",
       " '_node_key',\n",
       " '_nodes_by_depth',\n",
       " '_outbound_nodes',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_predict_loop',\n",
       " '_standardize_user_data',\n",
       " '_test_loop',\n",
       " '_trainable',\n",
       " '_updated_config',\n",
       " 'add',\n",
       " 'add_loss',\n",
       " 'add_update',\n",
       " 'add_weight',\n",
       " 'assert_input_compatibility',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'count_params',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'input',\n",
       " 'input_layers',\n",
       " 'input_layers_node_indices',\n",
       " 'input_layers_tensor_indices',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'legacy_from_config',\n",
       " 'legacy_get_config',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'loss_weights',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'metrics_tensors',\n",
       " 'model',\n",
       " 'name',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'output',\n",
       " 'output_layers',\n",
       " 'output_layers_node_indices',\n",
       " 'output_layers_tensor_indices',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'pop',\n",
       " 'predict',\n",
       " 'predict_classes',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_proba',\n",
       " 'regularizers',\n",
       " 'reset_states',\n",
       " 'run_internal_graph',\n",
       " 'sample_weight_mode',\n",
       " 'sample_weights',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stop_training',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'targets',\n",
       " 'test_on_batch',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'total_loss',\n",
       " 'train_on_batch',\n",
       " 'trainable',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'uses_learning_phase',\n",
       " 'weighted_metrics',\n",
       " 'weights']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.7750605018468985\n"
     ]
    }
   ],
   "source": [
    "nn_y_truth=[np.argmax(value) for value in nn_y_test]\n",
    "nn_y_pred=[np.argmax(value) for value in model.predict(nn_X_test)]\n",
    "print(\"Validation Accuracy : {}\".format(accuracy(nn_y_pred,nn_y_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.8519455333839387\n"
     ]
    }
   ],
   "source": [
    "nn_y_truth=[np.argmax(value) for value in nn_y_train]\n",
    "nn_y_pred=[np.argmax(value) for value in model.predict(nn_X_train)]\n",
    "print(\"Train Accuracy : {}\".format(accuracy(nn_y_pred,nn_y_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       976\n",
      "          1       0.89      0.83      0.86     11176\n",
      "          2       0.93      0.80      0.86     16169\n",
      "          3       0.80      0.50      0.62      1093\n",
      "          4       0.46      0.35      0.40        17\n",
      "          5       0.84      0.83      0.84      9552\n",
      "          6       0.84      0.84      0.84     13687\n",
      "          7       0.77      0.73      0.75      1283\n",
      "          8       0.74      0.83      0.78      1056\n",
      "          9       0.83      0.84      0.83      1662\n",
      "         10       0.70      0.68      0.69       983\n",
      "         11       0.83      0.78      0.80      1466\n",
      "         12       0.64      0.60      0.62      1116\n",
      "         13       0.86      0.85      0.85      1810\n",
      "         14       0.94      0.92      0.93      1404\n",
      "         15       0.69      0.90      0.78       854\n",
      "         16       0.81      0.76      0.78      1982\n",
      "         17       0.86      0.83      0.84       914\n",
      "         18       0.94      0.97      0.95      3423\n",
      "         19       0.88      0.89      0.89      2767\n",
      "         20       0.82      0.92      0.87       298\n",
      "         21       0.97      0.93      0.95      4826\n",
      "         22       0.80      0.83      0.81       378\n",
      "         23       0.75      0.51      0.61       318\n",
      "         24       0.82      0.79      0.80       572\n",
      "         25       0.85      0.84      0.84      2159\n",
      "         26       0.51      0.41      0.46       288\n",
      "         27       0.81      0.78      0.79      3399\n",
      "         28       0.94      0.87      0.90      1187\n",
      "         29       0.80      0.67      0.73      1484\n",
      "         30       0.84      0.79      0.81     18898\n",
      "         31       0.73      0.83      0.78      4801\n",
      "         32       0.79      0.70      0.75      1431\n",
      "         33       0.75      0.68      0.72      1634\n",
      "         34       0.87      0.63      0.73       145\n",
      "         35       0.87      0.92      0.89     27450\n",
      "         36       0.88      0.78      0.82     12830\n",
      "         37       0.91      0.85      0.88      3228\n",
      "         38       0.90      0.93      0.91       608\n",
      "         39       0.86      0.71      0.78      1611\n",
      "         40       0.78      0.94      0.85      3305\n",
      "         41       0.80      0.27      0.40        30\n",
      "         42       0.86      0.81      0.84      5850\n",
      "         43       0.92      0.96      0.94       264\n",
      "         44       0.89      0.96      0.93     35354\n",
      "         45       0.83      0.91      0.87      4721\n",
      "         46       0.77      0.30      0.43       381\n",
      "         47       0.69      0.64      0.67       903\n",
      "         48       0.69      0.67      0.68      4165\n",
      "         49       0.75      0.70      0.73       559\n",
      "         50       0.90      0.94      0.92      1175\n",
      "         51       0.79      0.78      0.78       901\n",
      "         52       0.90      0.93      0.91      9816\n",
      "         53       0.68      0.61      0.64      1089\n",
      "         54       1.00      0.47      0.64        17\n",
      "         55       0.76      0.88      0.82        81\n",
      "         56       0.71      1.00      0.83        17\n",
      "         57       0.76      0.89      0.82        18\n",
      "         58       0.79      0.85      0.82      9823\n",
      "         59       0.91      0.89      0.90      8934\n",
      "         60       0.71      0.51      0.59      1299\n",
      "         61       0.90      0.92      0.91     12279\n",
      "         62       0.87      0.86      0.86       188\n",
      "         63       0.87      0.80      0.84      1963\n",
      "         64       0.73      0.71      0.72      2518\n",
      "         65       0.78      0.78      0.78      1296\n",
      "         66       0.00      0.00      0.00         4\n",
      "         67       0.00      0.00      0.00         5\n",
      "         68       0.90      0.92      0.91      6522\n",
      "         69       0.84      0.87      0.85      3607\n",
      "         70       0.66      0.55      0.60      3533\n",
      "         71       0.78      0.73      0.75      5820\n",
      "         72       0.82      0.83      0.82      1824\n",
      "         73       0.89      0.92      0.90      8017\n",
      "         74       0.84      0.60      0.70       650\n",
      "         75       0.94      0.97      0.95      4496\n",
      "         76       0.89      0.93      0.91       581\n",
      "         77       0.74      0.66      0.70       190\n",
      "         78       0.72      0.69      0.70      1498\n",
      "         79       0.74      0.71      0.72      1168\n",
      "         80       0.77      0.83      0.80      1134\n",
      "         81       0.88      0.87      0.88      2831\n",
      "         82       0.79      0.40      0.53        75\n",
      "         83       0.65      0.62      0.63        21\n",
      "         84       0.88      0.92      0.90      3188\n",
      "         85       0.82      0.90      0.86      1484\n",
      "         86       0.77      0.40      0.53        25\n",
      "         87       0.79      0.74      0.76       974\n",
      "         88       0.73      0.65      0.69       422\n",
      "         89       0.76      0.86      0.81       442\n",
      "         90       0.77      0.79      0.78     14250\n",
      "         91       0.88      0.90      0.89       365\n",
      "         92       0.74      0.55      0.63       531\n",
      "         93       0.81      0.84      0.82       589\n",
      "         94       0.75      0.74      0.75       326\n",
      "         95       0.91      0.94      0.92      5204\n",
      "         96       0.88      0.70      0.78      2993\n",
      "         97       0.79      0.91      0.85      9615\n",
      "         98       0.78      0.36      0.49       399\n",
      "         99       0.91      0.71      0.80        87\n",
      "        100       0.90      0.92      0.91     20342\n",
      "        101       0.84      0.88      0.86       760\n",
      "        102       0.80      0.60      0.68       127\n",
      "        103       0.83      0.87      0.85      5227\n",
      "        104       0.86      0.88      0.87      3427\n",
      "        105       0.93      0.72      0.81       244\n",
      "        106       0.90      0.93      0.91       313\n",
      "        107       0.91      0.72      0.80       339\n",
      "        108       0.87      0.93      0.90      2058\n",
      "        109       0.87      0.91      0.89      1088\n",
      "\n",
      "avg / total       0.85      0.85      0.85    384676\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nn_y_truth,nn_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
