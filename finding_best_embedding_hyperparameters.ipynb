{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Embedder\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.grid_search import GridSearchCV as GS\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from preprocessing_pipeline import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data To Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data untuk klasifikasi kategori produk\n",
    "large_data_for_classification=pd.read_csv(\"data/big.csv\",header=None)\n",
    "large_data_for_classification.dropna(axis=0,inplace=True)\n",
    "\n",
    "# data untuk word embedding\n",
    "data_for_embedding=pd.read_fwf('data/products2m.txt',header=None)\n",
    "data_for_embedding[\"Product Title\"]=data_for_embedding[0]\n",
    "data_for_embedding=data_for_embedding[[\"Product Title\"]]\n",
    "data_for_embedding.dropna(inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_embedding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Word Embedder (Using fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parentheses_old(input_string):\n",
    "    result_string=input_string.lower()\n",
    "    target_parentheses=['-','/','[',']','!','(',')',',','.','+','-',\"'\",'\"',\"|\",\"*\",\"@\",\"#\",\"!\",\"<\",\">\",\":\",\";\",\"?\"]\n",
    "    for parentheses in target_parentheses:\n",
    "        result_string=result_string.replace(parentheses, ' ')\n",
    "    result_string=result_string.strip(' ').split()\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parentheses(input_string):\n",
    "    input_string=''.join(i for i in input_string if not i.isdigit())\n",
    "    result_string=input_string.lower()\n",
    "    target_parentheses=['-','/','[',']','!','(',')',',','.','+','-',\"'\",'\"',\"|\",\"*\",\"@\",\"#\",\"!\",\"<\",\">\",\":\",\";\",\"?\"]\n",
    "    for parentheses in target_parentheses:\n",
    "        result_string=result_string.replace(parentheses, ' ')\n",
    "    result_string=result_string.strip(' ').split()\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghapus karakter tidak penting dari data\n",
    "product_title=[remove_parentheses(value) for value in data_for_embedding[\"Product Title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Embedding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data=large_data_for_classification.sample(n=50000,random_state=1387178)\n",
    "mask = np.random.rand(len(sampled_data)) < 0.8\n",
    "train = sampled_data[mask]\n",
    "validation = sampled_data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON EMBEDDING WINDOW OF 1 | 2018-06-28 14:00:30.220999\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:01:17.235800\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:01:21.980418\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:01:21.981420\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 88s 2ms/step - loss: 2.6113\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 88s 2ms/step - loss: 2.2238\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 2.0384\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 88s 2ms/step - loss: 1.8866\n",
      "\tVALIDATION ACCURACY : 0.1553686293913904\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 2 | 2018-06-28 14:07:22.443479\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:08:24.282982\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:08:31.842052\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:08:31.842052\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 2.5368\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 91s 2ms/step - loss: 2.1423\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 1.9569\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 86s 2ms/step - loss: 1.8004\n",
      "\tVALIDATION ACCURACY : 0.15804057397328056\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 3 | 2018-06-28 14:14:31.538178\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:15:23.935534\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:15:28.571863\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:15:28.571863\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 87s 2ms/step - loss: 2.4974\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 2.1014\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 92s 2ms/step - loss: 1.9169\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 1.7569\n",
      "\tVALIDATION ACCURACY : 0.16665017318159328\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 5 | 2018-06-28 14:21:34.401014\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:22:46.808310\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:22:53.667551\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:22:53.667551\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - ETA: 0s - loss: 2.459 - 92s 2ms/step - loss: 2.4599\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 96s 2ms/step - loss: 2.0660\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 99s 3ms/step - loss: 1.8738\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 1.7156\n",
      "\tVALIDATION ACCURACY : 0.16674913409203365\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 7 | 2018-06-28 14:29:18.613482\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:30:17.844876\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:30:22.493270\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:30:22.493270\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 87s 2ms/step - loss: 2.4398\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 90s 2ms/step - loss: 2.0401\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 87s 2ms/step - loss: 1.8505\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 1.6861\n",
      "\tVALIDATION ACCURACY : 0.17357743691241959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for EMBEDDING_WINDOW in [1,2,3,5,7]:\n",
    "    print(\"TESTING ON EMBEDDING WINDOW OF {} | {}\".format(EMBEDDING_WINDOW,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=100, window=EMBEDDING_WINDOW, min_count=10, workers=4, sg=1, seed=SEED, min_n=5, iter=1)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(107, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=4, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON EMBEDDING WINDOW OF 11 | 2018-06-28 14:37:24.287958\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:38:29.156665\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:38:33.982530\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:38:33.983514\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 90s 2ms/step - loss: 2.4246\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 97s 2ms/step - loss: 2.0138\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 1.8194\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 92s 2ms/step - loss: 1.6497\n",
      "\tVALIDATION ACCURACY : 0.17219198416625434\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for EMBEDDING_WINDOW in [11]:\n",
    "    print(\"TESTING ON EMBEDDING WINDOW OF {} | {}\".format(EMBEDDING_WINDOW,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=100, window=EMBEDDING_WINDOW, min_count=10, workers=4, sg=1, seed=SEED, min_n=5, iter=1)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(107, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=4, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Embedding Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data=large_data_for_classification.sample(n=50000,random_state=1387178)\n",
    "mask = np.random.rand(len(sampled_data)) < 0.8\n",
    "train = sampled_data[mask]\n",
    "validation = sampled_data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for EMBEDDING_DIMENSION in [200]:\n",
    "    print(\"TESTING ON EMBEDDING DIMENSION OF {} | {}\".format(EMBEDDING_DIMENSION,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=EMBEDDING_DIMENSION, window=7, min_count=10, workers=4, sg=1, seed=SEED, min_n=5, iter=1)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(EMBEDDING_DIMENSION,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(107, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=2, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Embedding Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data=large_data_for_classification.sample(n=50000,random_state=1387178)\n",
    "mask = np.random.rand(len(sampled_data)) < 0.8\n",
    "train = sampled_data[mask]\n",
    "validation = sampled_data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for EMBEDDING_EPOCH in [1,5,10,20,40]:\n",
    "    print(\"TESTING ON EMBEDDING EPOCH OF {} | {}\".format(EMBEDDING_EPOCH,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=100, window=5, min_count=10, workers=4, sg=1, seed=SEED, min_n=5, iter=EMBEDDING_EPOCH)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(107, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=2, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
