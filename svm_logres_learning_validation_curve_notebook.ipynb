{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Embedder\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.grid_search import GridSearchCV as GS\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures as Poly\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Model's File Location\n",
    "\n",
    "version = \"version_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_pipeline import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/{}/word_embedder.pickle\".format(version), \"rb\") as file:\n",
    "    word_embedder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data To Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data untuk klasifikasi kategori produk\n",
    "data_for_classification=pd.read_csv(\"data/product_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_classification.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 400000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_for_classification=pd.read_csv(\"data/big.csv\",header=None)\n",
    "large_data_for_classification.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_for_classification.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess product title to 100-dimensional vector\n",
    "#and preprocess category name to integer label\n",
    "embedded_data, label_encoder = preprocessor.preprocess_data(\n",
    "    data_for_classification[\"Product Title\"],\n",
    "    data_for_classification[\"Category Name\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 400000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess product title to 100-dimensional vector\n",
    "#and preprocess category name to integer label\n",
    "large_embedded_data, large_label_encoder = preprocessor.preprocess_data(\n",
    "    large_data_for_classification[1],\n",
    "    large_data_for_classification[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_embedded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_embedded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/{}/label_encoder.pickle\".format(version), \"wb\") as file:\n",
    "    pickle.dump(large_label_encoder,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning & Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, title=\"Learning Curve\",\n",
    "                        n_jobs=4,cv=5, train_sizes=np.linspace(.1, 1.0, 5),scoring=\"accuracy\",ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(scoring)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, \n",
    "        X, \n",
    "        y, \n",
    "        cv=cv, \n",
    "        n_jobs=n_jobs, \n",
    "        train_sizes=train_sizes,\n",
    "        verbose=40, \n",
    "        scoring=scoring)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(estimator, X, y, hyperparameter, title=\"Validation Curve\",cv=5, \n",
    "                          param_range=np.logspace(-5, 5, 2),scoring=\"accuracy\"):\n",
    "\n",
    "\n",
    "    train_scores, valid_scores = validation_curve(\n",
    "        estimator, \n",
    "        X, \n",
    "        y, \n",
    "        \"C\",\n",
    "        cv=cv,\n",
    "        param_range=param_range,\n",
    "        verbose=40,\n",
    "        n_jobs=4, \n",
    "        scoring=scoring)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(hyperparameter)\n",
    "    plt.ylabel(scoring)\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.semilogx(param_range, valid_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, valid_scores_mean - valid_scores_std,\n",
    "                     valid_scores_mean + valid_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=large_embedded_data.copy()\n",
    "\n",
    "sampled_embedded_data=data.sample(n=len(data))\n",
    "\n",
    "# dimension_reducer=PCA(n_components=10)\n",
    "# reduced_features=dimension_reducer.fit_transform(sampled_embedded_data.drop(\"Labels\",axis=1))\n",
    "\n",
    "print(\"Start Time : {}\\n\".format(str(datetime.datetime.now())))\n",
    "\n",
    "plot_validation_curve(\n",
    "    estimator = LR(n_jobs=-1), \n",
    "    X = reduced_features, \n",
    "    y = sampled_embedded_data[\"Labels\"], \n",
    "    hyperparameter = \"C\", \n",
    "    title = \"Validation Curve\",\n",
    "    cv = 5,\n",
    "    param_range = np.logspace(-3, 3, 5),\n",
    "    scoring = \"accuracy\")\n",
    "\n",
    "print(\"\\nFinish Time : {}\".format(str(datetime.datetime.now())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=large_embedded_data.copy()\n",
    "\n",
    "sampled_embedded_data=data.sample(n=len(data))\n",
    "\n",
    "print(\"Start Time : {}\\n\".format(str(datetime.datetime.now())))\n",
    "\n",
    "plot_learning_curve(\n",
    "    estimator = LR(C=0.1,n_jobs=-1), \n",
    "    X = sampled_embedded_data.drop(\"Labels\",axis=1), \n",
    "    y = sampled_embedded_data[\"Labels\"], \n",
    "    title = \"Learning Curve (C=0.1)\",\n",
    "    n_jobs=4,\n",
    "    cv=2,\n",
    "    train_sizes = np.linspace(.1, 1, 5), \n",
    "    scoring=\"accuracy\")\n",
    "\n",
    "print(\"\\nFinish Time : {}\".format(str(datetime.datetime.now())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_embedded_data=embedded_data.sample(n=len(embedded_data)//10)\n",
    "\n",
    "print(\"Start Time : {}\\n\".format(str(datetime.datetime.now())))\n",
    "\n",
    "plot_validation_curve(\n",
    "    estimator = SVC(), \n",
    "    X = sampled_embedded_data.drop(\"Labels\",axis=1), \n",
    "    y = sampled_embedded_data[\"Labels\"], \n",
    "    hyperparameter = \"C\", \n",
    "    title = \"Validation Curve\",\n",
    "    cv = 5,\n",
    "    param_range = np.logspace(-1, 3, 5),\n",
    "    scoring = \"accuracy\")\n",
    "\n",
    "print(\"\\nFinish Time : {}\".format(str(datetime.datetime.now())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_embedded_data=embedded_data.sample(n=len(embedded_data))\n",
    "\n",
    "print(\"Start Time : {}\\n\".format(str(datetime.datetime.now())))\n",
    "\n",
    "plot_learning_curve(\n",
    "    estimator = SVC(C=10), \n",
    "    X = sampled_embedded_data.drop(\"Labels\",axis=1), \n",
    "    y = sampled_embedded_data[\"Labels\"], \n",
    "    title = \"Learning Curve (C=10)\",\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    train_sizes = np.linspace(.1, 1, 5), \n",
    "    scoring=\"accuracy\")\n",
    "\n",
    "print(\"\\nFinish Time : {}\".format(str(datetime.datetime.now())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
