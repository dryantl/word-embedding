{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Embedder\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.grid_search import GridSearchCV as GS\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures as Poly\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Model's File Location\n",
    "\n",
    "version = \"version_4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_pipeline import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/{}/word_embedder.pickle\".format(version), \"rb\") as file:\n",
    "    word_embedder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<preprocessing_pipeline.preprocessing at 0x284efad198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.fasttext.FastText at 0x284efad320>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data To Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_for_classification=pd.read_csv(\"data/big.csv\",header=None)\n",
    "large_data_for_classification.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hardware</td>\n",
       "      <td>KINGSTON+KVR1333D3N9</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musik</td>\n",
       "      <td>power+amplifier+wisdom+</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outwear-motor</td>\n",
       "      <td>jas%20hujan%20anak</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>celana</td>\n",
       "      <td>Celana+bahan+formal</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komputer</td>\n",
       "      <td>Preset+lightroom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                        1       2\n",
       "0       hardware     KINGSTON+KVR1333D3N9  1510.0\n",
       "1          musik  power+amplifier+wisdom+    62.0\n",
       "2  outwear-motor       jas%20hujan%20anak   391.0\n",
       "3         celana      Celana+bahan+formal   288.0\n",
       "4       komputer         Preset+lightroom     1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data_for_classification.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_category_mapper=pd.read_csv(\"category_mapping.csv\",index_col=0)\n",
    "\n",
    "category_mapper={}\n",
    "for i in raw_category_mapper.index:\n",
    "    category_mapper[raw_category_mapper[\"l2\"][i]]=raw_category_mapper[\"l1\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_category=[category_mapper[value] for value in large_data_for_classification[0]]\n",
    "large_data_for_classification[0]=new_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>komputer</td>\n",
       "      <td>KINGSTON+KVR1333D3N9</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hobi_dan_koleksi</td>\n",
       "      <td>power+amplifier+wisdom+</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor</td>\n",
       "      <td>jas%20hujan%20anak</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fashion_wanita</td>\n",
       "      <td>Celana+bahan+formal</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komputer</td>\n",
       "      <td>Preset+lightroom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                        1       2\n",
       "0          komputer     KINGSTON+KVR1333D3N9  1510.0\n",
       "1  hobi_dan_koleksi  power+amplifier+wisdom+    62.0\n",
       "2             motor       jas%20hujan%20anak   391.0\n",
       "3    fashion_wanita      Celana+bahan+formal   288.0\n",
       "4          komputer         Preset+lightroom     1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data_for_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess product title to 100-dimensional vector\n",
    "#and preprocess category name to integer label\n",
    "large_embedded_data, large_label_encoder = preprocessor.preprocess_data(\n",
    "    large_data_for_classification[1],\n",
    "    large_data_for_classification[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.275295</td>\n",
       "      <td>-0.438877</td>\n",
       "      <td>0.347446</td>\n",
       "      <td>0.420617</td>\n",
       "      <td>-0.655826</td>\n",
       "      <td>-0.893736</td>\n",
       "      <td>-0.268864</td>\n",
       "      <td>0.091967</td>\n",
       "      <td>0.253759</td>\n",
       "      <td>-0.407018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060328</td>\n",
       "      <td>0.121378</td>\n",
       "      <td>-0.236838</td>\n",
       "      <td>1.079665</td>\n",
       "      <td>-0.457356</td>\n",
       "      <td>-0.169778</td>\n",
       "      <td>-0.031531</td>\n",
       "      <td>-0.533224</td>\n",
       "      <td>-0.596936</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225148</td>\n",
       "      <td>1.786125</td>\n",
       "      <td>0.616444</td>\n",
       "      <td>-0.040366</td>\n",
       "      <td>-0.316455</td>\n",
       "      <td>0.551794</td>\n",
       "      <td>-0.654612</td>\n",
       "      <td>-0.795263</td>\n",
       "      <td>1.905773</td>\n",
       "      <td>0.121287</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.228765</td>\n",
       "      <td>-0.147218</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>-0.156134</td>\n",
       "      <td>-0.311683</td>\n",
       "      <td>0.178662</td>\n",
       "      <td>0.349768</td>\n",
       "      <td>-0.696280</td>\n",
       "      <td>0.755887</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.227633</td>\n",
       "      <td>-0.858571</td>\n",
       "      <td>-0.520574</td>\n",
       "      <td>0.164235</td>\n",
       "      <td>-2.518956</td>\n",
       "      <td>-0.054563</td>\n",
       "      <td>1.125197</td>\n",
       "      <td>1.010731</td>\n",
       "      <td>0.801415</td>\n",
       "      <td>1.163370</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.043469</td>\n",
       "      <td>2.140666</td>\n",
       "      <td>-2.564406</td>\n",
       "      <td>2.357174</td>\n",
       "      <td>1.715434</td>\n",
       "      <td>-0.115448</td>\n",
       "      <td>-2.115783</td>\n",
       "      <td>-2.267262</td>\n",
       "      <td>-1.784940</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.103322</td>\n",
       "      <td>-0.371176</td>\n",
       "      <td>1.602983</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.338218</td>\n",
       "      <td>-2.489933</td>\n",
       "      <td>-1.299406</td>\n",
       "      <td>1.602620</td>\n",
       "      <td>1.629507</td>\n",
       "      <td>1.238133</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.477074</td>\n",
       "      <td>-2.458070</td>\n",
       "      <td>-1.160693</td>\n",
       "      <td>1.680575</td>\n",
       "      <td>0.541392</td>\n",
       "      <td>1.173590</td>\n",
       "      <td>-2.529253</td>\n",
       "      <td>-1.546401</td>\n",
       "      <td>1.537661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.096464</td>\n",
       "      <td>-0.166233</td>\n",
       "      <td>0.577785</td>\n",
       "      <td>0.399365</td>\n",
       "      <td>-0.718592</td>\n",
       "      <td>-0.854424</td>\n",
       "      <td>0.374337</td>\n",
       "      <td>-0.318422</td>\n",
       "      <td>-0.018439</td>\n",
       "      <td>0.245501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487409</td>\n",
       "      <td>0.230962</td>\n",
       "      <td>-0.333771</td>\n",
       "      <td>0.158394</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.179707</td>\n",
       "      <td>0.396101</td>\n",
       "      <td>-0.485040</td>\n",
       "      <td>-0.054236</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.275295 -0.438877  0.347446  0.420617 -0.655826 -0.893736 -0.268864   \n",
       "1  0.225148  1.786125  0.616444 -0.040366 -0.316455  0.551794 -0.654612   \n",
       "2  0.227633 -0.858571 -0.520574  0.164235 -2.518956 -0.054563  1.125197   \n",
       "3  1.103322 -0.371176  1.602983  0.019839  0.338218 -2.489933 -1.299406   \n",
       "4 -0.096464 -0.166233  0.577785  0.399365 -0.718592 -0.854424  0.374337   \n",
       "\n",
       "          7         8         9   ...          91        92        93  \\\n",
       "0  0.091967  0.253759 -0.407018   ...    0.060328  0.121378 -0.236838   \n",
       "1 -0.795263  1.905773  0.121287   ...   -2.228765 -0.147218  0.039434   \n",
       "2  1.010731  0.801415  1.163370   ...   -3.043469  2.140666 -2.564406   \n",
       "3  1.602620  1.629507  1.238133   ...   -1.477074 -2.458070 -1.160693   \n",
       "4 -0.318422 -0.018439  0.245501   ...   -0.487409  0.230962 -0.333771   \n",
       "\n",
       "         94        95        96        97        98        99  Labels  \n",
       "0  1.079665 -0.457356 -0.169778 -0.031531 -0.533224 -0.596936      10  \n",
       "1 -0.156134 -0.311683  0.178662  0.349768 -0.696280  0.755887       6  \n",
       "2  2.357174  1.715434 -0.115448 -2.115783 -2.267262 -1.784940      12  \n",
       "3  1.680575  0.541392  1.173590 -2.529253 -1.546401  1.537661       3  \n",
       "4  0.158394  0.055914  0.179707  0.396101 -0.485040 -0.054236      10  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_embedded_data[\"sum\"]=large_embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_embedded_data=large_embedded_data.loc[large_embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392527, 101)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=large_embedded_data.copy()\n",
    "sampled_embedded_data=data.sample(n=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_X_train,nn_X_test,nn_y_train,nn_y_test=train_test_split(sampled_embedded_data.drop(\"Labels\",axis=1),to_categorical(sampled_embedded_data[\"Labels\"]),test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "model.add(Dense(1500, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dense(750, activation='relu'))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384676 samples, validate on 7851 samples\n",
      "Epoch 12/12\n",
      "384676/384676 [==============================] - 452s 1ms/step - loss: 0.3092 - acc: 0.8940 - val_loss: 0.5687 - val_acc: 0.8491\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(nn_X_train, nn_y_train,initial_epoch=11, epochs=12, batch_size=100, validation_data=(nn_X_test,nn_y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_85val_90sing_20classes.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.8589988536492167\n"
     ]
    }
   ],
   "source": [
    "nn_y_truth=[np.argmax(value) for value in nn_y_test]\n",
    "nn_y_pred=[np.argmax(value) for value in model.predict(nn_X_test)]\n",
    "print(\"Validation Accuracy : {}\".format(accuracy(nn_y_pred,nn_y_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.901197371294284\n"
     ]
    }
   ],
   "source": [
    "nn_y_truth=[np.argmax(value) for value in nn_y_train]\n",
    "nn_y_pred=[np.argmax(value) for value in model.predict(nn_X_train)]\n",
    "print(\"Train Accuracy : {}\".format(accuracy(nn_y_pred,nn_y_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28525b8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "support=[18901,4163,45911,23344,3616,51494,45244,7200,11880,5949,26305,16711,42462,26672,6538,3717,3031,28350,12843,345]\n",
    "fscore=[80,79,88,86,89,96,91,73,93,88,93,91,96,88,91,87,81,87,94,79]\n",
    "plt.scatter(support,fscore)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.68      0.71       376\n",
      "          1       0.78      0.75      0.77        83\n",
      "          2       0.81      0.91      0.86       946\n",
      "          3       0.88      0.79      0.83       481\n",
      "          4       0.82      0.82      0.82        72\n",
      "          5       0.95      0.94      0.95      1082\n",
      "          6       0.85      0.86      0.85       912\n",
      "          7       0.61      0.59      0.60       137\n",
      "          8       0.88      0.92      0.90       238\n",
      "          9       0.75      0.69      0.72       109\n",
      "         10       0.89      0.89      0.89       550\n",
      "         11       0.86      0.85      0.86       355\n",
      "         12       0.94      0.95      0.94       884\n",
      "         13       0.87      0.80      0.83       527\n",
      "         14       0.79      0.86      0.82       111\n",
      "         15       0.86      0.74      0.80        85\n",
      "         16       0.69      0.66      0.67        67\n",
      "         17       0.77      0.80      0.79       577\n",
      "         18       0.92      0.92      0.92       249\n",
      "         19       0.75      0.60      0.67        10\n",
      "\n",
      "avg / total       0.86      0.86      0.86      7851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nn_y_truth,nn_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-2bdcc3f2d2f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_y_truth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn_y_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"support\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "classification_report(nn_y_truth,nn_y_pred)[\"support\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=large_embedded_data.copy()\n",
    "sampled_embedded_data=data.sample(n=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_X_train,nn_X_test,nn_y_train,nn_y_test=train_test_split(sampled_embedded_data.drop(\"Labels\",axis=1),to_categorical(sampled_embedded_data[\"Labels\"]),test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2500, input_shape=(100,), activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(1500, activation='relu'))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"Adagrad\", loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384676 samples, validate on 7851 samples\n",
      "Epoch 1/5\n",
      "384676/384676 [==============================] - 759s 2ms/step - loss: 0.8648 - acc: 0.7660 - val_loss: 0.6498 - val_acc: 0.8100\n",
      "Epoch 2/5\n",
      "384676/384676 [==============================] - 767s 2ms/step - loss: 0.5942 - acc: 0.8240 - val_loss: 0.5725 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "384676/384676 [==============================] - 765s 2ms/step - loss: 0.5006 - acc: 0.8488 - val_loss: 0.5384 - val_acc: 0.8429\n",
      "Epoch 4/5\n",
      "384676/384676 [==============================] - 767s 2ms/step - loss: 0.4376 - acc: 0.8648 - val_loss: 0.5270 - val_acc: 0.8475\n",
      "Epoch 5/5\n",
      "384676/384676 [==============================] - 777s 2ms/step - loss: 0.3929 - acc: 0.8752 - val_loss: 0.5235 - val_acc: 0.8517\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(nn_X_train, nn_y_train,epochs=5, batch_size=100, validation_data=(nn_X_test,nn_y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384676 samples, validate on 7851 samples\n",
      "Epoch 6/7\n",
      "384676/384676 [==============================] - 772s 2ms/step - loss: 0.3609 - acc: 0.8823 - val_loss: 0.5217 - val_acc: 0.8524\n",
      "Epoch 7/7\n",
      "384676/384676 [==============================] - 801s 2ms/step - loss: 0.3367 - acc: 0.8874 - val_loss: 0.5164 - val_acc: 0.8559\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(nn_X_train, nn_y_train,initial_epoch=5, epochs=7, batch_size=100, validation_data=(nn_X_test,nn_y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384676 samples, validate on 7851 samples\n",
      "Epoch 9/10\n",
      "384676/384676 [==============================] - 796s 2ms/step - loss: 0.3046 - acc: 0.8937 - val_loss: 0.5260 - val_acc: 0.8596\n",
      "Epoch 10/10\n",
      "384676/384676 [==============================] - 796s 2ms/step - loss: 0.2937 - acc: 0.8961 - val_loss: 0.5281 - val_acc: 0.8575\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(nn_X_train, nn_y_train,initial_epoch=8, epochs=10, batch_size=100, validation_data=(nn_X_test,nn_y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_90sing_86val_20classes.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384676 samples, validate on 7851 samples\n",
      "Epoch 11/13\n",
      "384676/384676 [==============================] - 831s 2ms/step - loss: 0.2855 - acc: 0.8974 - val_loss: 0.5296 - val_acc: 0.8607\n",
      "Epoch 12/13\n",
      "384676/384676 [==============================] - 827s 2ms/step - loss: 0.2782 - acc: 0.8987 - val_loss: 0.5295 - val_acc: 0.8612\n",
      "Epoch 13/13\n",
      "  1000/384676 [..............................] - ETA: 12:53 - loss: 0.2386 - acc: 0.90"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-03e868e4585c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_X_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schedule_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36m_schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_schedule_in_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_later\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_schedule_in_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(nn_X_train, nn_y_train,initial_epoch=10, epochs=13, batch_size=100, validation_data=(nn_X_test,nn_y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_90sing_86val_20classes.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
