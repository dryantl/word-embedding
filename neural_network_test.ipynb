{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Embedder\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.grid_search import GridSearchCV as GS\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures as Poly\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Model's File Location\n",
    "\n",
    "version = \"version_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_pipeline import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/{}/label_encoder.pickle\".format(version), \"rb\") as file:\n",
    "    label_encoder = pickle.load(file)\n",
    "\n",
    "with open(\"model/{}/word_embedder.pickle\".format(version), \"rb\") as file:\n",
    "    word_embedder = pickle.load(file)\n",
    "\n",
    "neural_network = load_model(\"model/{}/neural_network.h5\".format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=preprocessing(word_embedder.vector_size,word_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.fasttext.FastText at 0xe47a892f98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0xe47ccb07b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data To Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_for_classification=pd.read_csv(\"data/big.csv\",header=None)\n",
    "large_data_for_classification.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hardware</td>\n",
       "      <td>KINGSTON+KVR1333D3N9</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musik</td>\n",
       "      <td>power+amplifier+wisdom+</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outwear-motor</td>\n",
       "      <td>jas%20hujan%20anak</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>celana</td>\n",
       "      <td>Celana+bahan+formal</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komputer</td>\n",
       "      <td>Preset+lightroom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                        1       2\n",
       "0       hardware     KINGSTON+KVR1333D3N9  1510.0\n",
       "1          musik  power+amplifier+wisdom+    62.0\n",
       "2  outwear-motor       jas%20hujan%20anak   391.0\n",
       "3         celana      Celana+bahan+formal   288.0\n",
       "4       komputer         Preset+lightroom     1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data_for_classification.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess product title to 100-dimensional vector\n",
    "#and preprocess category name to integer label\n",
    "large_embedded_data = preprocessor.preprocess_data(\n",
    "    large_data_for_classification[1],\n",
    "    large_data_for_classification[0],\n",
    "    label_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.036711</td>\n",
       "      <td>-0.336128</td>\n",
       "      <td>-0.161967</td>\n",
       "      <td>0.099742</td>\n",
       "      <td>-0.092715</td>\n",
       "      <td>0.196797</td>\n",
       "      <td>0.281012</td>\n",
       "      <td>-0.571889</td>\n",
       "      <td>0.054769</td>\n",
       "      <td>-0.252326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493046</td>\n",
       "      <td>0.427457</td>\n",
       "      <td>-0.021196</td>\n",
       "      <td>0.340428</td>\n",
       "      <td>-0.027172</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>0.118060</td>\n",
       "      <td>0.153254</td>\n",
       "      <td>0.065467</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.151489</td>\n",
       "      <td>-1.193317</td>\n",
       "      <td>-0.412542</td>\n",
       "      <td>0.074164</td>\n",
       "      <td>-1.053800</td>\n",
       "      <td>0.283322</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>-0.714775</td>\n",
       "      <td>-0.282685</td>\n",
       "      <td>-0.205421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560397</td>\n",
       "      <td>1.276572</td>\n",
       "      <td>-0.248248</td>\n",
       "      <td>0.154423</td>\n",
       "      <td>-0.181553</td>\n",
       "      <td>-0.448146</td>\n",
       "      <td>-0.126884</td>\n",
       "      <td>-0.248857</td>\n",
       "      <td>1.153092</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.236827</td>\n",
       "      <td>-0.166503</td>\n",
       "      <td>-0.234478</td>\n",
       "      <td>0.278609</td>\n",
       "      <td>-0.010111</td>\n",
       "      <td>0.248139</td>\n",
       "      <td>0.202832</td>\n",
       "      <td>-0.236111</td>\n",
       "      <td>0.063634</td>\n",
       "      <td>-0.342770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090241</td>\n",
       "      <td>0.113574</td>\n",
       "      <td>0.081810</td>\n",
       "      <td>0.114736</td>\n",
       "      <td>-0.101849</td>\n",
       "      <td>-0.024248</td>\n",
       "      <td>-0.114954</td>\n",
       "      <td>-0.040353</td>\n",
       "      <td>-0.044465</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.053166</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>-1.529572</td>\n",
       "      <td>1.458670</td>\n",
       "      <td>-0.734888</td>\n",
       "      <td>-0.503057</td>\n",
       "      <td>-0.532288</td>\n",
       "      <td>-0.022648</td>\n",
       "      <td>0.070379</td>\n",
       "      <td>-1.529616</td>\n",
       "      <td>...</td>\n",
       "      <td>1.294445</td>\n",
       "      <td>-0.273994</td>\n",
       "      <td>1.718030</td>\n",
       "      <td>0.060490</td>\n",
       "      <td>-1.941472</td>\n",
       "      <td>1.189055</td>\n",
       "      <td>-0.650072</td>\n",
       "      <td>-0.596036</td>\n",
       "      <td>0.285584</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.162186</td>\n",
       "      <td>-0.530731</td>\n",
       "      <td>-0.356022</td>\n",
       "      <td>0.209101</td>\n",
       "      <td>-0.282881</td>\n",
       "      <td>0.324258</td>\n",
       "      <td>0.422291</td>\n",
       "      <td>-0.745394</td>\n",
       "      <td>-0.038498</td>\n",
       "      <td>-0.477472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860707</td>\n",
       "      <td>0.729105</td>\n",
       "      <td>-0.046928</td>\n",
       "      <td>0.239313</td>\n",
       "      <td>0.133619</td>\n",
       "      <td>-0.398247</td>\n",
       "      <td>0.280034</td>\n",
       "      <td>0.195425</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.036711 -0.336128 -0.161967  0.099742 -0.092715  0.196797  0.281012   \n",
       "1 -0.151489 -1.193317 -0.412542  0.074164 -1.053800  0.283322  0.306509   \n",
       "2 -0.236827 -0.166503 -0.234478  0.278609 -0.010111  0.248139  0.202832   \n",
       "3 -0.053166  0.007892 -1.529572  1.458670 -0.734888 -0.503057 -0.532288   \n",
       "4 -0.162186 -0.530731 -0.356022  0.209101 -0.282881  0.324258  0.422291   \n",
       "\n",
       "          7         8         9   ...          91        92        93  \\\n",
       "0 -0.571889  0.054769 -0.252326   ...    0.493046  0.427457 -0.021196   \n",
       "1 -0.714775 -0.282685 -0.205421   ...    1.560397  1.276572 -0.248248   \n",
       "2 -0.236111  0.063634 -0.342770   ...   -0.090241  0.113574  0.081810   \n",
       "3 -0.022648  0.070379 -1.529616   ...    1.294445 -0.273994  1.718030   \n",
       "4 -0.745394 -0.038498 -0.477472   ...    0.860707  0.729105 -0.046928   \n",
       "\n",
       "         94        95        96        97        98        99  Labels  \n",
       "0  0.340428 -0.027172 -0.208955  0.118060  0.153254  0.065467      45  \n",
       "1  0.154423 -0.181553 -0.448146 -0.126884 -0.248857  1.153092      68  \n",
       "2  0.114736 -0.101849 -0.024248 -0.114954 -0.040353 -0.044465      73  \n",
       "3  0.060490 -1.941472  1.189055 -0.650072 -0.596036  0.285584      24  \n",
       "4  0.239313  0.133619 -0.398247  0.280034  0.195425  0.424736      59  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396099, 101)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_embedded_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_job',\n",
       " '_get_job_params',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_dict',\n",
       " '_load_model_params',\n",
       " '_load_specials',\n",
       " '_load_vectors',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_set_train_params',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_update_job_params',\n",
       " '_worker_loop',\n",
       " 'accuracy',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'bucket',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'callbacks',\n",
       " 'cbow_mean',\n",
       " 'clear_sims',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'cum_table',\n",
       " 'doesnt_match',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'evaluate_word_pairs',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'init_sims',\n",
       " 'iter',\n",
       " 'layer1_size',\n",
       " 'load',\n",
       " 'load_binary_data',\n",
       " 'load_fasttext_format',\n",
       " 'max_n',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'min_n',\n",
       " 'model_trimmed_post_training',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'n_similarity',\n",
       " 'negative',\n",
       " 'num_ngram_vectors',\n",
       " 'random',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'sg',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'struct_unpack',\n",
       " 'syn0_lockf',\n",
       " 'syn0_ngrams_lockf',\n",
       " 'syn0_vocab_lockf',\n",
       " 'syn1',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'trainables',\n",
       " 'vector_size',\n",
       " 'vocabulary',\n",
       " 'window',\n",
       " 'wmdistance',\n",
       " 'word_ngrams',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(word_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_product_class(query,preprocessor=preprocessor,classifier=neural_network,label_encoder=label_encoder):\n",
    "    no_parentheses=preprocessor.remove_parentheses(query)\n",
    "    embedded_query=preprocessor.vectorize_sentence(no_parentheses).reshape(-1,100)\n",
    "    prediction=classifier.predict_classes(embedded_query)\n",
    "    class_prediction=label_encoder.inverse_transform(prediction[0])\n",
    "    return class_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=neural_network\n",
    "data=large_embedded_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_embedded_data=data.sample(n=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8037409839459327\n"
     ]
    }
   ],
   "source": [
    "# truth=data[\"Labels\"]\n",
    "# pred=model.predict_classes(data.drop(\"Labels\",axis=1))\n",
    "# # print(\"Accuracy : {}\".format(accuracy(pred,truth)))\n",
    "# print(classification_report(truth,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
