{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Useful Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "D:\\Program\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Embedder\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.grid_search import GridSearchCV as GS\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from preprocessing_pipeline import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data To Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data untuk klasifikasi kategori produk\n",
    "large_data_for_classification=pd.read_csv(\"data/big.csv\",header=None)\n",
    "large_data_for_classification.dropna(axis=0,inplace=True)\n",
    "\n",
    "# data untuk word embedding\n",
    "data_for_embedding=pd.read_fwf('data/products2m.txt',header=None)\n",
    "data_for_embedding[\"Product Title\"]=data_for_embedding[0]\n",
    "data_for_embedding=data_for_embedding[[\"Product Title\"]]\n",
    "data_for_embedding.dropna(inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC LENOVO IC300s-i5(4460)-VGA with LED-19,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prosessor intel core i5 4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LENOVO All in One aio310-0kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PC Lenovo aio510-crid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 570-P034D Win 10 Home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Product Title\n",
       "0  PC LENOVO IC300s-i5(4460)-VGA with LED-19,5\n",
       "1                 prosessor intel core i5 4440\n",
       "2                LENOVO All in One aio310-0kid\n",
       "3                        PC Lenovo aio510-crid\n",
       "4            HP Pavilion 570-P034D Win 10 Home"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_embedding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parentheses_old(input_string):\n",
    "    result_string=input_string.lower()\n",
    "    target_parentheses=['-','/','[',']','!','(',')',',','.','+','-',\"'\",'\"',\"|\",\"*\",\"@\",\"#\",\"!\",\"<\",\">\",\":\",\";\",\"?\"]\n",
    "    for parentheses in target_parentheses:\n",
    "        result_string=result_string.replace(parentheses, ' ')\n",
    "    result_string=result_string.strip(' ').split()\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parentheses(input_string):\n",
    "    input_string=''.join(i for i in input_string if not i.isdigit())\n",
    "    result_string=input_string.lower()\n",
    "    target_parentheses=['-','/','[',']','!','(',')',',','.','+','-',\"'\",'\"',\"|\",\"*\",\"@\",\"#\",\"!\",\"<\",\">\",\":\",\";\",\"?\"]\n",
    "    for parentheses in target_parentheses:\n",
    "        result_string=result_string.replace(parentheses, ' ')\n",
    "    result_string=result_string.strip(' ').split()\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghapus karakter tidak penting dari data\n",
    "product_title=[remove_parentheses(value) for value in data_for_embedding[\"Product Title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Embedding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data=large_data_for_classification.sample(n=50000,random_state=1387178)\n",
    "mask = np.random.rand(len(sampled_data)) < 0.8\n",
    "train = sampled_data[mask]\n",
    "validation = sampled_data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON EMBEDDING WINDOW OF 1 | 2018-06-28 14:00:30.220999\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:01:17.235800\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:01:21.980418\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:01:21.981420\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 88s 2ms/step - loss: 2.6113\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 88s 2ms/step - loss: 2.2238\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 2.0384\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 88s 2ms/step - loss: 1.8866\n",
      "\tVALIDATION ACCURACY : 0.1553686293913904\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 2 | 2018-06-28 14:07:22.443479\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:08:24.282982\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:08:31.842052\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:08:31.842052\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 2.5368\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 91s 2ms/step - loss: 2.1423\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 1.9569\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 86s 2ms/step - loss: 1.8004\n",
      "\tVALIDATION ACCURACY : 0.15804057397328056\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 3 | 2018-06-28 14:14:31.538178\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:15:23.935534\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:15:28.571863\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:15:28.571863\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 87s 2ms/step - loss: 2.4974\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 2.1014\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 92s 2ms/step - loss: 1.9169\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 1.7569\n",
      "\tVALIDATION ACCURACY : 0.16665017318159328\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 5 | 2018-06-28 14:21:34.401014\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:22:46.808310\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:22:53.667551\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:22:53.667551\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - ETA: 0s - loss: 2.459 - 92s 2ms/step - loss: 2.4599\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 96s 2ms/step - loss: 2.0660\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 99s 3ms/step - loss: 1.8738\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 1.7156\n",
      "\tVALIDATION ACCURACY : 0.16674913409203365\n",
      "\n",
      "TESTING ON EMBEDDING WINDOW OF 7 | 2018-06-28 14:29:18.613482\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:30:17.844876\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:30:22.493270\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:30:22.493270\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 87s 2ms/step - loss: 2.4398\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 90s 2ms/step - loss: 2.0401\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 87s 2ms/step - loss: 1.8505\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 89s 2ms/step - loss: 1.6861\n",
      "\tVALIDATION ACCURACY : 0.17357743691241959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for EMBEDDING_WINDOW in [1,2,3,5,7]:\n",
    "    print(\"TESTING ON EMBEDDING WINDOW OF {} | {}\".format(EMBEDDING_WINDOW,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=100, window=EMBEDDING_WINDOW, min_count=10, workers=4, sg=1, seed=SEED, min_n=5, iter=1)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(107, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=4, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON EMBEDDING WINDOW OF 11 | 2018-06-28 14:37:24.287958\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 14:38:29.156665\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 14:38:33.982530\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 14:38:33.983514\n",
      "Epoch 1/4\n",
      "39471/39471 [==============================] - 90s 2ms/step - loss: 2.4246\n",
      "Epoch 2/4\n",
      "39471/39471 [==============================] - 97s 2ms/step - loss: 2.0138\n",
      "Epoch 3/4\n",
      "39471/39471 [==============================] - 93s 2ms/step - loss: 1.8194\n",
      "Epoch 4/4\n",
      "39471/39471 [==============================] - 92s 2ms/step - loss: 1.6497\n",
      "\tVALIDATION ACCURACY : 0.17219198416625434\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for EMBEDDING_WINDOW in [11]:\n",
    "    print(\"TESTING ON EMBEDDING WINDOW OF {} | {}\".format(EMBEDDING_WINDOW,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=100, window=EMBEDDING_WINDOW, min_count=10, workers=4, sg=1, seed=SEED, min_n=5, iter=1)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(107, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=4, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Embedding Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data=large_data_for_classification.sample(n=50000,random_state=1387178)\n",
    "mask = np.random.rand(len(sampled_data)) < 0.8\n",
    "train = sampled_data[mask]\n",
    "validation = sampled_data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON EMBEDDING DIMENSION OF 200 | 2018-06-28 15:49:15.826871\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 15:50:45.477079\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 15:50:54.013261\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 15:50:54.013261\n",
      "Epoch 1/2\n",
      "39360/39360 [==============================] - 110s 3ms/step - loss: 2.4499\n",
      "Epoch 2/2\n",
      "39360/39360 [==============================] - 96s 2ms/step - loss: 2.0552\n",
      "\tVALIDATION ACCURACY : 0.05413328121946453\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for EMBEDDING_DIMENSION in [200]:\n",
    "    print(\"TESTING ON EMBEDDING DIMENSION OF {} | {}\".format(EMBEDDING_DIMENSION,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=EMBEDDING_DIMENSION, window=7, min_count=10, workers=4, sg=1, seed=123972, min_n=5, iter=1)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(EMBEDDING_DIMENSION,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(108, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=2, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "39360/39360 [==============================] - 95s 2ms/step - loss: 1.8584\n",
      "Epoch 4/4\n",
      "39360/39360 [==============================] - 96s 2ms/step - loss: 1.6978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]),initial_epoch=2, epochs=4, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Embedding Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted,truth):\n",
    "    result=[int(value) for value in np.array(predicted)==np.array(truth)]\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data=large_data_for_classification.sample(n=50000,random_state=1387178)\n",
    "mask = np.random.rand(len(sampled_data)) < 0.8\n",
    "train = sampled_data[mask]\n",
    "validation = sampled_data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON EMBEDDING EPOCH OF 5 | 2018-06-28 16:00:47.446773\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 16:06:00.536481\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 16:06:06.707894\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 16:06:06.707894\n",
      "Epoch 1/2\n",
      "39641/39641 [==============================] - 93s 2ms/step - loss: 2.1676\n",
      "Epoch 2/2\n",
      "39641/39641 [==============================] - 96s 2ms/step - loss: 1.7120\n",
      "\tVALIDATION ACCURACY : 0.05561132302750452\n",
      "\n",
      "\n",
      "TESTING ON EMBEDDING EPOCH OF 10 | 2018-06-28 16:09:20.115675\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 16:20:11.609734\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 16:20:17.795171\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 16:20:17.795171\n",
      "Epoch 1/2\n",
      "39641/39641 [==============================] - 89s 2ms/step - loss: 2.1154\n",
      "Epoch 2/2\n",
      "39641/39641 [==============================] - 89s 2ms/step - loss: 1.6391\n",
      "\tVALIDATION ACCURACY : 0.052198353744228064\n",
      "\n",
      "\n",
      "TESTING ON EMBEDDING EPOCH OF 20 | 2018-06-28 16:23:20.202106\n",
      "\tEMBEDDER CONSTRUCTED | 2018-06-28 16:45:05.510317\n",
      "\tPREPROCESSING FINISHED | 2018-06-28 16:45:12.112876\n",
      "\n",
      "\tTRAINING CLASSIFIER | 2018-06-28 16:45:12.113880\n",
      "Epoch 1/2\n",
      "39641/39641 [==============================] - 92s 2ms/step - loss: 2.0869\n",
      "Epoch 2/2\n",
      "39641/39641 [==============================] - 94s 2ms/step - loss: 1.5936\n",
      "\tVALIDATION ACCURACY : 0.0522987351937362\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for EMBEDDING_EPOCH in [5,10,20]:\n",
    "    print(\"TESTING ON EMBEDDING EPOCH OF {} | {}\".format(EMBEDDING_EPOCH,str(datetime.datetime.now())))\n",
    "    word_embedder = FastText(product_title, size=100, window=7, min_count=10, workers=4, sg=1, seed=132984, min_n=5, iter=EMBEDDING_EPOCH)\n",
    "    print(\"\\tEMBEDDER CONSTRUCTED | {}\".format(str(datetime.datetime.now())))\n",
    "    preprocessor=preprocessing(word_embedder.vector_size,word_embedder)\n",
    "    embedded_data,label_encoder=preprocessor.preprocess_data(train[1],train[0])\n",
    "    validation_set,validation_label_encoder=preprocessor.preprocess_data(validation[1],validation[0])\n",
    "    embedded_data[\"sum\"]=embedded_data.drop([\"Labels\"],axis=1).sum(axis=1)\n",
    "    embedded_data=embedded_data.loc[embedded_data[\"sum\"]!=0].drop(\"sum\",axis=1)\n",
    "    print(\"\\tPREPROCESSING FINISHED | {}\".format(str(datetime.datetime.now())))\n",
    "    \n",
    "    print(\"\\n\\tTRAINING CLASSIFIER | {}\".format(str(datetime.datetime.now())))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2000, input_shape=(100,), activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(108, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), epochs=2, batch_size=32, shuffle=True)\n",
    "    \n",
    "    truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "    pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "    result.append(accuracy(pred,truth))\n",
    "    print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "39641/39641 [==============================] - 88s 2ms/step - loss: 1.3299\n",
      "Epoch 4/4\n",
      "39641/39641 [==============================] - 88s 2ms/step - loss: 1.1100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(embedded_data.drop(\"Labels\",axis=1),to_categorical(embedded_data[\"Labels\"]), initial_epoch=2,epochs=4, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tVALIDATION ACCURACY : 0.057016663320618347\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truth=[np.argmax(value) for value in to_categorical(validation_set[\"Labels\"])]\n",
    "pred=[np.argmax(value) for value in model.predict(validation_set.drop(\"Labels\",axis=1))]\n",
    "result.append(accuracy(pred,truth))\n",
    "print(\"\\tVALIDATION ACCURACY : {}\\n\\n\".format(accuracy(pred,truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word_embedder_20_new.pickle\", \"wb\") as file:\n",
    "    pickle.dump(word_embedder, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
